var e=Object.defineProperty,t=(t,o,n)=>((t,o,n)=>o in t?e(t,o,{enumerable:!0,configurable:!0,writable:!0,value:n}):t[o]=n)(t,"symbol"!=typeof o?o+"":o,n);class o{static setMockMode(e){this.mockConfig={...this.mockConfig,...e}}static isMockEnabled(){return this.mockConfig.enabled}static async generateMockResponse(e,t){this.responseCount++;const o=this.mockConfig.delay||50;if(await new Promise(e=>setTimeout(e,o)),this.mockConfig.errorRate&&Math.random()<this.mockConfig.errorRate)return this.generateErrorResponse(e);const n=!!this.mockConfig.refusalRate&&Math.random()<this.mockConfig.refusalRate;return{status:200,headers:{"content-type":"application/json","x-mock-response":"true"},body:this.generateProviderSpecificResponse(e,t.body,n),latencyMs:o}}static generateProviderSpecificResponse(e,t,o){const n=Math.floor(Date.now()/1e3),s=o?"I cannot and will not provide that information.":this.generateRandomContent(t);switch(e){case"openai-chat":return{id:`chatcmpl-mock-${this.responseCount}`,object:"chat.completion",created:n,model:t.model||"gpt-3.5-turbo",choices:[{index:0,message:{role:"assistant",content:s,...o&&{refusal:"This request violates content policy."}},finish_reason:"stop"}],usage:{prompt_tokens:10,completion_tokens:15,total_tokens:25}};case"anthropic":return{id:`msg-mock-${this.responseCount}`,type:"message",role:"assistant",content:[{type:"text",text:s}],model:t.model||"claude-3-sonnet-20240229",stop_reason:"end_turn",stop_sequence:null,usage:{input_tokens:10,output_tokens:15}};case"ollama-chat":return{model:t.model||"llama2",created_at:(new Date).toISOString(),message:{role:"assistant",content:s},done:!0,total_duration:1e9,load_duration:5e8,prompt_eval_count:10,prompt_eval_duration:2e8,eval_count:15,eval_duration:3e8};case"ollama-generate":return{model:t.model||"llama2",created_at:(new Date).toISOString(),response:s,done:!0,context:[1,2,3,4,5],total_duration:1e9,load_duration:5e8,prompt_eval_count:10,prompt_eval_duration:2e8,eval_count:15,eval_duration:3e8};case"openrouter":return{id:`gen-mock-${this.responseCount}`,choices:[{finish_reason:"stop",message:{role:"assistant",content:s}}],created:n,model:t.model||"openai/gpt-3.5-turbo",object:"chat.completion",usage:{prompt_tokens:10,completion_tokens:15,total_tokens:25}};default:return{id:`mock-${this.responseCount}`,content:s,model:t.model||"unknown",created:n}}}static generateRandomContent(e){const t=["The answer is 42.","Based on the analysis, the result is positive.","Here's what I found: Lorem ipsum dolor sit amet.","The data suggests a correlation of 0.85.","Processing complete. Status: Success.","According to my calculations, the value is 3.14159.","The system returned: OK","Analysis indicates optimal performance.","Result: Test passed successfully.","Output generated: Hello, world!"],o=e.messages||[],n=o[o.length-1]?.content||"",s=n.toLowerCase();if(s.includes("extract")){return`The extracted value is: ${(n.match(/\d+/g)||[])[0]||"42"}`}return"json_object"===e.response_format?.type||s.includes("json")?JSON.stringify({status:"success",value:Math.floor(100*Math.random()),timestamp:(new Date).toISOString()}):t[Math.floor(Math.random()*t.length)]}static generateErrorResponse(e){const t=["Rate limit exceeded","Invalid API key","Model not found","Request timeout","Service unavailable"],o=t[Math.floor(Math.random()*t.length)];switch(e){case"openai-chat":return{status:429,headers:{"content-type":"application/json"},body:{error:{message:o,type:"rate_limit_error",code:"rate_limit_exceeded"}},latencyMs:10};case"anthropic":return{status:400,headers:{"content-type":"application/json"},body:{type:"error",error:{type:"invalid_request_error",message:o}},latencyMs:10};default:return{status:500,headers:{"content-type":"application/json"},body:{error:o},latencyMs:10}}}static reset(){this.responseCount=0,this.mockConfig={enabled:!1,delay:50,errorRate:0,refusalRate:0}}}t(o,"mockConfig",{enabled:!1,delay:50,errorRate:0,refusalRate:0}),t(o,"responseCount",0);export{o as MockProviderService};

var e=Object.defineProperty,t=(t,r,s)=>((t,r,s)=>r in t?e(t,r,{enumerable:!0,configurable:!0,writable:!0,value:s}):t[r]=s)(t,"symbol"!=typeof r?r+"":r,s);import{D as r,d as s,r as o,b as a}from"./index-Bz5Ugese.js";import{L as n,c as i}from"./llm-CAe4LcMC.js";import"./vendor-DdqHZeTC.js";import"./db-ftwlfnxb.js";import"./apiLogger-wE3EW76_.js";import"./safeJson-BfKuju6h.js";const l=class e{constructor(){t(this,"dbService"),this.dbService=r.getInstance()}static getInstance(){return e.instance||(e.instance=new e),e.instance}async resolveDesignVariables(e,t=[]){const r={},s=e.variables||{};for(const[a,n]of Object.entries(s))Array.isArray(n)&&(r[a]=n);const o=e.variable_list_refs||{};for(const[a,n]of Object.entries(o)){let e=t.find(e=>e.id===n);if(!e){const t=await this.dbService.read("variable_lists",n);t.success&&t.data&&(e=t.data)}e&&e.values&&(r[a]=e.values)}return r}async resolveVariablesWithAttributes(e,t=[]){const r={},s={};if(e.variables)for(const[o,a]of Object.entries(e.variables))r[o]=a,s[o]=a.map(()=>({}));if(e.variable_list_refs)for(const[o,a]of Object.entries(e.variable_list_refs)){let e=t.find(e=>e.id===a);if(!e){const t=await this.dbService.read("variable_lists",a);t.success&&t.data&&(e=t.data)}e&&e.values&&(r[o]=e.values,"attributed"===e.category&&e.attributed_items?s[o]=e.attributed_items.map(e=>e.attributes):s[o]=e.values.map(()=>({})))}return{values:r,attributes:s}}extractTemplateVariables(e){if("string"!=typeof e)return[];const t=/\{\{([^}]+)\}\}/g,r=new Set;let s;for(;null!==(s=t.exec(e));){const e=s[1].trim();e&&/^[a-zA-Z_][a-zA-Z0-9_]*$/.test(e)&&r.add(e)}return Array.from(r)}async validateTemplateVariables(e,t=[]){const r=this.extractTemplateVariables(e.prompt_template||""),s=await this.resolveDesignVariables(e,t),o=Object.keys(s),a=r.filter(e=>!o.includes(e)),n=o.filter(e=>!r.includes(e)),i=[];return n.length>0&&i.push(`Unused variables: ${n.join(", ")}`),{valid:0===a.length,missingVariables:a,unusedVariables:n,warnings:i}}processTemplate(e,t){let r=e;for(const[s,o]of Object.entries(t))if(!s.includes("_")||e.includes(`{{${s}}}`)){const e=s.replace(/[.*+?^${}()|[\]\\]/g,"\\$&"),t=new RegExp(`{{\\s*${e}\\s*}}`,"g");r=r.replace(t,o)}return r}generateCombinationsWithAttributes(e){const{values:t,attributes:r}=e,s=Object.keys(t);if(0===s.length)return[{}];const o=[];return function e(a,n){if(a===s.length)return void o.push({...n});const i=s[a],l=t[i],c=r[i]||[];for(let t=0;t<l.length;t++){const r=l[t],s=c[t]||{};n[i]=r;for(const[e,t]of Object.entries(s))n[`${i}_${e}`]=String(t);e(a+1,n),delete n[i];for(const e of Object.keys(s))delete n[`${i}_${e}`]}}(0,{}),o}};t(l,"instance");let c=l;class u{classifyError(e){return e instanceof n?this.classifyLLMError(e):this.classifyGenericError(e)}classifyLLMError(e){const t=e.statusCode,r=e.message.toLowerCase(),s=e.provider;if(408===t)return{isRetryable:!0,isRateLimit:!1,errorCategory:"timeout",reason:"API call timeout - retryable with exponential backoff"};if(429===t){const t=this.extractRetryAfterSeconds(e);return{isRetryable:!0,isRateLimit:!0,retryAfterSeconds:t,errorCategory:"rate_limit",reason:`Rate limited - retry after ${t||"exponential backoff"} seconds`}}return t&&t>=500?{isRetryable:!0,isRateLimit:!1,errorCategory:"server_error",reason:`Server error (${t}) - retryable`}:401===t||403===t?{isRetryable:!1,isRateLimit:!1,errorCategory:"authentication",reason:"Authentication failed - check API key"}:t&&t>=400&&t<500?this.isRetryableClientError(r,s)?{isRetryable:!0,isRateLimit:!1,errorCategory:"client_error",reason:"Potentially temporary client error - retryable"}:{isRetryable:!1,isRateLimit:!1,errorCategory:"client_error",reason:`Client error (${t}) - not retryable`}:this.classifyProviderSpecificError(r,s)}classifyGenericError(e){const t=e.message.toLowerCase();return t.includes("network")||t.includes("connection")||t.includes("timeout")||t.includes("aborted")||t.includes("fetch")?{isRetryable:!0,isRateLimit:!1,errorCategory:"network",reason:"Network error - retryable"}:{isRetryable:!1,isRateLimit:!1,errorCategory:"unknown",reason:"Unknown error type - not retryable by default"}}classifyProviderSpecificError(e,t){return"openai"===t&&(e.includes("overloaded")||e.includes("engine overloaded"))?{isRetryable:!0,isRateLimit:!1,errorCategory:"server_error",reason:"OpenAI engine overloaded - retryable"}:"anthropic"===t&&(e.includes("overloaded")||e.includes("capacity"))?{isRetryable:!0,isRateLimit:!1,errorCategory:"server_error",reason:"Anthropic capacity issue - retryable"}:"openrouter"===t&&(e.includes("upstream")||e.includes("provider error"))?{isRetryable:!0,isRateLimit:!1,errorCategory:"server_error",reason:"OpenRouter upstream error - retryable"}:{isRetryable:!1,isRateLimit:!1,errorCategory:"unknown",reason:"Provider-specific error - not retryable by default"}}isRetryableClientError(e,t){return["temporarily","temporarily unavailable","too many requests","quota exceeded","rate limit","throttled"].some(t=>e.includes(t))}extractRetryAfterSeconds(e){if(e.details&&"object"==typeof e.details){const t=e.details.retry_after||e.details["retry-after"];if("number"==typeof t)return t;if("string"==typeof t){const e=parseInt(t,10);if(!isNaN(e))return e}}}}const d=new u;class p{constructor(e){t(this,"config"),this.config={maxRetries:5,baseDelayMs:2e3,maxDelayMs:6e4,jitterFactor:.1,backoffMultiplier:2,rateLimitBackoffMs:3e4,...e}}calculateDelay(e,t,r){if(t&&r)return Math.min(1e3*r,this.config.maxDelayMs);if(t)return this.config.rateLimitBackoffMs;const s=this.config.baseDelayMs*Math.pow(this.config.backoffMultiplier,e-1),o=s+s*this.config.jitterFactor*(2*Math.random()-1);return Math.min(Math.max(o,this.config.baseDelayMs),this.config.maxDelayMs)}shouldRetry(e){return e<=this.config.maxRetries}createRetryAttempt(e,t,r,s){return{attemptNumber:e,delayMs:t,timestamp:(new Date).toISOString(),error:r.message,errorCategory:s}}getConfig(){return{...this.config}}updateConfig(e){this.config={...this.config,...e}}calculateMaxRetryTime(){let e=0;for(let t=1;t<=this.config.maxRetries;t++)e+=this.calculateDelay(t,!1);return e}getRetrySummary(){const e=Math.round(this.calculateMaxRetryTime()/1e3);return`Up to ${this.config.maxRetries} retries over ~${e} seconds`}}const g=new p,m={openai:new p({maxRetries:5,baseDelayMs:3e3,rateLimitBackoffMs:6e4}),anthropic:new p({maxRetries:5,baseDelayMs:2e3,rateLimitBackoffMs:3e4}),openrouter:new p({maxRetries:6,baseDelayMs:5e3,rateLimitBackoffMs:45e3}),ollama:new p({maxRetries:3,baseDelayMs:1e3,rateLimitBackoffMs:5e3})};class f{constructor(){t(this,"locked",!1),t(this,"queue",[])}async acquire(e){return new Promise((t,r)=>{const s=async()=>{if(this.locked)this.queue.push(s);else{this.locked=!0;try{const r=await e();t(r)}catch(o){r(o)}finally{this.locked=!1;const e=this.queue.shift();e&&e()}}};s()})}isLocked(){return this.locked}getQueueLength(){return this.queue.length}}class y{constructor(){t(this,"abortController",null),t(this,"activeTasks",new Set),t(this,"completedCount",0),t(this,"errorClassifier",new u),t(this,"progressLock",new f),t(this,"retryTimeouts",new Set)}async processRun(e,t){this.cleanup(),this.completedCount=e.completed_tasks||0,this.abortController=new AbortController;try{const r=await s.designs.get(e.design_id);if(!r)throw new Error("Design not found");const o=await s.models.where("id").anyOf(e.models).toArray();if(0===o.length){const t=await s.models.toArray();throw console.error("TaskProcessor Error: No models found!"),console.error("  Run model IDs:",JSON.stringify(e.models)),console.error("  Available model IDs:",JSON.stringify(t.map(e=>e.id))),console.error("  Available models:",JSON.stringify(t.map(e=>({id:e.id,enabled:e.enabled})))),new Error("No models found")}const a=await this.generateTasks(e,r,o);await s.runs.update(e.id,{total_tasks:a.length,status:"running",updated_at:(new Date).toISOString()});const n=(await s.tasks.bulkAdd(a,{allKeys:!0})).map((e,t)=>({id:e,task:a[t]})),i=[];for(let s=0;s<t.concurrency;s++){const a=this.processWorker(n,o,e,r,t);i.push(a),console.log(`[TaskProcessor] Created worker ${s+1}/${t.concurrency}`)}console.log(`[TaskProcessor] Starting ${i.length} workers, waiting for completion...`);const l=Date.now();await Promise.all(i);const c=Date.now()-l;console.log(`[TaskProcessor] All workers completed in ${c}ms, updating run status...`),console.log("[TaskProcessor] Querying final tasks...");const u=await s.tasks.where("run_id").equals(e.id).toArray();console.log(`[TaskProcessor] Got ${u.length} final tasks, filtering...`);const d=u.filter(e=>"completed"===e.status).length,p=u.filter(e=>"error"===e.status).length;console.log(`[TaskProcessor] Completed: ${d}, Errors: ${p}`),console.log("[TaskProcessor] Updating run record..."),await s.runs.update(e.id,{status:"completed",completed_tasks:d,error_count:p,updated_at:(new Date).toISOString()}),console.log("[TaskProcessor] Run update complete!")}finally{this.cleanup()}}async generateTasks(e,t,r){const s=[],o=await this.getVariableValuesWithAttributes(t),a=this.generateCombinationsWithAttributes(o);for(const n of r)for(let r=1;r<=e.parameters.repetitions_per_prompt;r++)for(const o of a){const a=c.getInstance().processTemplate(t.prompt_template,o);s.push({run_id:e.id,model:n.id,prompt:a,variables:o,repetition:r,status:"pending",created_at:(new Date).toISOString()})}return s}async getVariableValues(e){const t=c.getInstance();return await t.resolveDesignVariables(e)}async getVariableValuesWithAttributes(e){const t=c.getInstance();return await t.resolveVariablesWithAttributes(e)}generateCombinations(e){const t=Object.keys(e);if(0===t.length)return[{}];const r=[];return function s(o,a){if(o===t.length)return void r.push({...a});const n=t[o];for(const t of e[n])a[n]=t,s(o+1,a)}(0,{}),r}generateCombinationsWithAttributes(e){const{values:t,attributes:r}=e,s=Object.keys(t);if(0===s.length)return[{}];const o=[];return function e(a,n){if(a===s.length)return void o.push({...n});const i=s[a],l=t[i],c=r[i];for(let t=0;t<l.length;t++){const r=l[t],s=c[t];n[i]=r;for(const[e,t]of Object.entries(s))n[`${i}_${e}`]=String(t);e(a+1,n);for(const e of Object.keys(s))delete n[`${i}_${e}`]}}(0,{}),o}async processWorker(e,t,r,a,n){const l=Math.random().toString(36).substring(7);for(console.log(`[Worker ${l}] Starting worker, initial queue length: ${e.length}`);e.length>0&&!this.abortController?.signal.aborted;){console.log(`[Worker ${l}] Loop iteration - queue length: ${e.length}, active tasks: ${this.activeTasks.size}, completed: ${this.completedCount}`);const u=e.length,d=e.shift(),p=e.length;if(console.log(`[Worker ${l}] Queue shift - before: ${u}, after: ${p}, got:`,d?`task ${d.id}`:"undefined"),!d){console.log(`[Worker ${l}] No item received, breaking from worker loop`);break}const{id:f,task:y}=d;console.log(`[Worker ${l}] About to process task ${f}`),this.activeTasks.add(f);const h=t.find(e=>e.id===y.model);if(h)try{if(this.abortController?.signal.aborted){await s.tasks.update(f,{status:"cancelled"});continue}if(console.log(`[TaskProcessor] Starting task ${f}`),await s.tasks.update(f,{status:"processing"}),console.log(`[TaskProcessor] Task ${f} status updated to processing`),this.abortController?.signal.aborted){await s.tasks.update(f,{status:"cancelled"});continue}const e=await i({model:h.id,prompt:y.prompt,temperature:r.parameters.temperature,max_tokens:r.parameters.max_tokens,output_format:a.output_format,output_type:a.output_type},h);if(this.abortController?.signal.aborted){await s.tasks.update(f,{status:"cancelled"});continue}let t={};"json"===a.output_format&&void 0!==e.extracted_value?t={answer:e.extracted_value}:a.extract_pattern&&(t=this.parseResults(e.content,a.extract_pattern)),console.log(`[TaskProcessor] Completing task ${f}`),await s.tasks.update(f,{status:"completed",result:e.content,parsed_results:t,response_time:e.response_time,usage:e.usage,api_call_log:e.api_call_log,completed_at:(new Date).toISOString()}),console.log(`[TaskProcessor] Task ${f} updated to completed`),console.log(`[Worker ${l}] Starting research log for task ${f}`);const c=Date.now();e.api_call_log&&await o.logAPICall(f,h.id,{request_url:e.api_call_log.request.url,response_status:e.api_call_log.response.status,response_time_ms:e.api_call_log.response.timing_ms,cost_estimate:e.api_call_log.cost_estimate.estimated_cost_usd,tokens_used:{input:e.api_call_log.cost_estimate.input_tokens,output:e.api_call_log.cost_estimate.output_tokens}});const u=Date.now()-c;if(console.log(`[Worker ${l}] Research log completed for task ${f} in ${u}ms`),await this.updateProgress(r,l,f),n.onTaskComplete){const e=await s.tasks.get(f);e&&n.onTaskComplete(e)}n.onProgress&&n.onProgress(this.completedCount,r.total_tasks)}catch(c){const t=await s.tasks.get(f);if(!t){console.error(`[TaskProcessor] Task ${f} not found for retry logic`),this.activeTasks.delete(f);continue}const a=this.errorClassifier.classifyError(c),i=t.retry_count||0,u=5;if(a.isRetryable&&i<u){const n=(m[h.provider]||g).calculateDelay(i+1,a.isRateLimit,a.retryAfterSeconds),l={attemptNumber:i+1,delayMs:n,timestamp:(new Date).toISOString(),error:c instanceof Error?c.message:String(c),errorCategory:a.errorCategory};await s.tasks.update(f,{retry_count:i+1,retry_attempts:[...t.retry_attempts||[],l],last_retry_at:(new Date).toISOString(),retry_after:a.retryAfterSeconds?new Date(Date.now()+1e3*a.retryAfterSeconds).toISOString():void 0}),await o.logRetryAttempt(f,{attempt_number:l.attemptNumber,delay_ms:l.delayMs,error_category:l.errorCategory,error_message:l.error,will_retry_at:new Date(Date.now()+n).toISOString()}),console.log(`[TaskProcessor] Task ${f} will retry in ${n}ms (attempt ${l.attemptNumber}/${u})`);const p=setTimeout(async()=>{if(this.retryTimeouts.delete(p),!this.abortController?.signal.aborted){const t=await s.runs.get(r.id);t&&"running"===t.status?e.push(d):console.log(`[TaskProcessor] Task ${f} retry cancelled - run is ${t?.status||"missing"}`)}},n);this.retryTimeouts.add(p)}else{const e=c instanceof Error?c.message:String(c),t=i>=u?`Max retries (${u}) exceeded. Last error: ${e}`:`Non-retryable error: ${e}`;if(await s.tasks.update(f,{status:"error",error:t,completed_at:(new Date).toISOString()}),await this.updateProgressWithError(r,l,f),await o.logTaskFailure(f,{final_error:t,retry_count:i,error_category:a.errorCategory,is_retryable:a.isRetryable}),n.onTaskError){const e=await s.tasks.get(f);e&&n.onTaskError(e,c)}n.onProgress&&n.onProgress(this.completedCount,r.total_tasks)}}finally{console.log(`[Worker ${l}] Removing task ${f} from active tasks`),this.activeTasks.delete(f),console.log(`[Worker ${l}] Task ${f} removed, active tasks now: ${this.activeTasks.size}`)}else console.error(`[TaskProcessor] Model ${y.model} not found for task ${f}`),await s.tasks.update(f,{status:"error",error:`Model ${y.model} not found`,completed_at:(new Date).toISOString()}),this.activeTasks.delete(f)}console.log(`[Worker ${l}] Worker loop ended - queue length: ${e.length}, active tasks: ${this.activeTasks.size}, completed: ${this.completedCount}`)}stop(){this.abortController?.abort(),this.cleanup()}pause(){this.stop()}resume(){}cleanup(){this.abortController&&(this.abortController.abort(),this.abortController=null),this.retryTimeouts.forEach(e=>clearTimeout(e)),this.retryTimeouts.clear(),this.activeTasks.clear()}dispose(){this.cleanup()}async updateProgress(e,t,r){this.abortController?.signal.aborted?console.log(`[Worker ${t}] Skipping progress update for task ${r} - run is stopped`):await this.progressLock.acquire(async()=>{if(this.abortController?.signal.aborted)return;const o=await s.runs.get(e.id);if(!o||"stopped"===o.status)return void console.log(`[Worker ${t}] Run ${e.id} is ${o?.status||"missing"}, skipping progress update`);this.completedCount+=1,console.log(`[TaskProcessor] Completed count now: ${this.completedCount}`),console.log(`[Worker ${t}] Starting run progress update for task ${r}`);const a=Date.now();await s.runs.update(e.id,{completed_tasks:this.completedCount,updated_at:(new Date).toISOString()});const n=Date.now()-a;console.log(`[Worker ${t}] Run progress updated for task ${r} in ${n}ms`)})}async updateProgressWithError(e,t,r){this.abortController?.signal.aborted?console.log(`[Worker ${t}] Skipping error progress update for task ${r} - run is stopped`):await this.progressLock.acquire(async()=>{if(this.abortController?.signal.aborted)return;const o=await s.runs.get(e.id);o&&"stopped"!==o.status?(this.completedCount+=1,await s.runs.update(e.id,{completed_tasks:this.completedCount,error_count:(e.error_count||0)+1,updated_at:(new Date).toISOString()}),console.log(`[Worker ${t}] Progress updated with error for task ${r}, completed: ${this.completedCount}`)):console.log(`[Worker ${t}] Run ${e.id} is ${o?.status||"missing"}, skipping error update`)})}parseResults(e,t){if(!t||!e)return{response:e};try{const s="string"==typeof t?{match:t,replace:void 0}:t,o=new RegExp(s.match,"gm"),a={};let n,i=0;const l=1e3,c=100;let u=0;for(;null!==(n=o.exec(e))&&i<l&&u<c;)if(i++,u++,n.index===o.lastIndex&&o.lastIndex++,n.groups)Object.assign(a,n.groups);else if(n.length>1){for(let e=1;e<n.length;e++)if(void 0!==n[e]){a[1===u?`match_${e}`:`match_${u}_${e}`]=n[e]}}else{a[1===u?"match":`match_${u}`]=n[0]}if(i>=l&&(console.warn("Pattern parsing stopped due to complexity limit:",t),a._parsing_warning="Parsing stopped due to complexity limit"),u>=c&&(console.warn("Pattern parsing stopped due to match limit:",t),a._parsing_warning="Parsing stopped due to match limit"),s.replace)for(const[e,t]of Object.entries(a))if("string"==typeof t&&"_parsing_warning"!==e)try{const r=new RegExp(s.match,"g"),o=t.replace(r,s.replace);a[e]=o}catch(r){console.warn("Error applying replace pattern:",r)}for(const[e,t]of Object.entries(a))if("string"==typeof t&&"_parsing_warning"!==e){const r=t.replace(/,/g,""),s=parseFloat(r);!isNaN(s)&&isFinite(s)?a[e]=s:a[e]=r}return a}catch(s){return console.error("Error parsing results with pattern:",t,s),{_parsing_error:s instanceof Error?s.message:"Unknown parsing error"}}}}class h{async analyzeFailedTasks(e){const t=await s.tasks.where("[run_id+status]").equals([e,"error"]).toArray();let r=0,o=0,a=0,n=0,i=0;const l=new Date;for(const s of t){if((s.retry_count||0)>=g.getConfig().maxRetries)a++;else{if(s.retry_after){if(l<new Date(s.retry_after)){n++;continue}}if(s.error){const e=new Error(s.error);d.classifyError(e).isRetryable?(r++,i++):o++}else o++}}const c=this.estimateRetryTime(i);return{totalFailedTasks:t.length,retryableFailedTasks:r,nonRetryableFailedTasks:o,maxRetriesExceeded:a,rateLimitedTasks:n,readyToRetry:i,estimatedRetryTime:c}}async getRetryableTasks(e){const t=await s.tasks.where("[run_id+status]").equals([e,"error"]).toArray(),r=new Date,o=[];for(const s of t){if(!((s.retry_count||0)>=g.getConfig().maxRetries)){if(s.retry_after){if(r<new Date(s.retry_after))continue}if(s.error){const e=new Error(s.error);d.classifyError(e).isRetryable&&o.push(s)}}}return o}async retryFailedTasks(e,t){const r=Date.now(),a=await s.runs.get(e);if(!a)throw new Error("Run not found");const n=await s.designs.get(a.design_id);if(!n)throw new Error("Design not found");const i=await s.models.where("id").anyOf(a.models).toArray();if(0===i.length)throw new Error("No models found");const l=await this.getRetryableTasks(e);if(0===l.length)return{totalTasks:0,successfulRetries:0,failedRetries:0,skippedTasks:0,results:[],duration:Date.now()-r};await o.logOperation("run",e,"run_start",{operation:"bulk_retry",total_tasks:l.length});const c=[];let u=0,d=0,p=0;const g=new Array(t?.maxConcurrency||3).fill(null),m=[...l],f=async()=>{for(;m.length>0;){const r=m.shift();if(!r)break;try{const e=await this.retryTask(r,a,n,i);c.push(e),e.success?u++:d++,t?.onTaskRetry&&t.onTaskRetry(e)}catch(e){const t={taskId:r.id,success:!1,error:e instanceof Error?e.message:String(e),retryAttempt:{attemptNumber:(r.retry_count||0)+1,delayMs:0,timestamp:(new Date).toISOString(),error:e instanceof Error?e.message:String(e),errorCategory:"retry_error"}};c.push(t),d++}p++,t?.onProgress&&t.onProgress(p,l.length)}};return await Promise.all(g.map(()=>f())),await this.updateRunRetryStats(e),await o.logOperation("run",e,"run_complete",{operation:"bulk_retry",successful_retries:u,failed_retries:d,duration_ms:Date.now()-r}),{totalTasks:l.length,successfulRetries:u,failedRetries:d,skippedTasks:0,results:c,duration:Date.now()-r}}async retryTask(e,t,r,a){const n=a.find(t=>t.id===e.model);if(!n)throw new Error(`Model ${e.model} not found`);const l=(e.retry_count||0)+1,c=m[n.provider]||g;if(l>c.getConfig().maxRetries)throw new Error(`Max retries (${c.getConfig().maxRetries}) exceeded`);await s.tasks.update(e.id,{status:"processing",retry_count:l,last_retry_at:(new Date).toISOString()});try{const a=await i({model:n.id,prompt:e.prompt,temperature:t.parameters.temperature,max_tokens:t.parameters.max_tokens,output_format:r.output_format,output_type:r.output_type},n);let c={};"json"===r.output_format&&void 0!==a.extracted_value?c={answer:a.extracted_value}:r.extract_pattern&&(c={content:a.content});const u={attemptNumber:l,delayMs:0,timestamp:(new Date).toISOString(),error:"",errorCategory:"success"},d=[...e.retry_attempts||[],u];return await s.tasks.update(e.id,{status:"completed",result:a.content,parsed_results:c,response_time:a.response_time,usage:a.usage,api_call_log:a.api_call_log,completed_at:(new Date).toISOString(),retry_attempts:d,retry_after:void 0}),a.api_call_log&&await o.logAPICall(e.id,n.id,{request_url:a.api_call_log.request.url,response_status:a.api_call_log.response.status,response_time_ms:a.api_call_log.response.timing_ms,cost_estimate:a.api_call_log.cost_estimate.estimated_cost_usd,tokens_used:{input:a.api_call_log.cost_estimate.input_tokens,output:a.api_call_log.cost_estimate.output_tokens}}),{taskId:e.id,success:!0,retryAttempt:u}}catch(u){const t=d.classifyError(u),r={attemptNumber:l,delayMs:0,timestamp:(new Date).toISOString(),error:u.message,errorCategory:t.errorCategory},o=[...e.retry_attempts||[],r];let a;if(t.isRateLimit&&t.retryAfterSeconds){const e=new Date;e.setSeconds(e.getSeconds()+t.retryAfterSeconds),a=e.toISOString()}return await s.tasks.update(e.id,{status:"error",error:u.message,completed_at:(new Date).toISOString(),retry_attempts:o,retry_after:a}),{taskId:e.id,success:!1,error:u.message,retryAttempt:r}}}async updateRunRetryStats(e){const t=await s.tasks.where("run_id").equals(e).toArray(),r=t.filter(e=>"completed"===e.status).length,o=t.filter(e=>"error"===e.status).length;await s.runs.update(e,{completed_tasks:r,error_count:o,updated_at:(new Date).toISOString()})}estimateRetryTime(e){if(0===e)return"0 seconds";const t=e/3*5e3;return t<6e4?`~${Math.round(t/1e3)} seconds`:t<36e5?`~${Math.round(t/6e4)} minutes`:`~${Math.round(t/36e5)} hours`}}const _=new class{constructor(){t(this,"processors",new Map),t(this,"retryService",new h)}async startRun(e){const t=a(),r=await t.getRunById(e);if(!r)throw new Error("Run not found");if(this.processors.has(e))throw new Error("Run is already being processed");const s=new y;this.processors.set(e,s);try{await s.processRun(r,{concurrency:r.parameters.concurrency||3,onProgress:async r=>{await t.updateRun(e,{completed_tasks:r})},onTaskComplete:e=>{},onTaskError:(e,t)=>{}})}finally{const t=this.processors.get(e);t&&(t.dispose(),this.processors.delete(e))}}stopRun(e){const t=this.processors.get(e);t&&(t.stop(),t.dispose(),this.processors.delete(e))}pauseRun(e){const t=this.processors.get(e);t&&t.pause()}resumeRun(e){}isRunning(e){return this.processors.has(e)}stopAll(){for(const[,e]of this.processors)e.stop(),e.dispose();this.processors.clear()}async retryFailedTasks(e,t){if(this.processors.has(e))throw new Error("Cannot retry tasks while run is still processing");const r=await this.retryService.retryFailedTasks(e,{maxConcurrency:t?.concurrency||3,onProgress:t?.onProgress});return{retriedCount:r.totalTasks,successCount:r.successfulRetries,failedCount:r.failedRetries,errors:r.results.filter(e=>!e.success).map(e=>({taskId:e.taskId,error:e.error||"Unknown error"}))}}async getRetryAnalysis(e){const t=await this.retryService.analyzeFailedTasks(e);return{totalFailed:t.totalFailedTasks,retryableCount:t.retryableFailedTasks,nonRetryableCount:t.nonRetryableFailedTasks,errorsByCategory:{},tasksByError:[]}}dispose(){this.stopAll()}};export{_ as runProcessor};

import{u as e,t,b as a,a as n}from"./designs-db-Cu90pWLg.js";import{u as s}from"./variables-db-DFlmKEoQ.js";import{u as r}from"./models-db-CmLn_MUd.js";import{u as o,T as i}from"./trials-db-By9dbEH8.js";import{p as l}from"./registry-aRYPBFJZ.js";import{u as p}from"./settings-db-BVOtWTBg.js";import{h as c,i as u,_ as d}from"./index-JX8mTFJZ.js";import{M as m}from"./ModelSelectionTable-Dq708mA7.js";import{d as v,f,c as g,w as y,o as h,S as _,U as b,X as x,W as k,Y as w,k as S,a2 as A,a3 as T,a4 as $,F as C,G as P,a5 as I,u as E}from"./vendor-BxfGckcK.js";const R={class:"trial-top-bar"},O={class:"top-bar-left"},j={key:0,class:"variable-info"},M={class:"combinations-count"},U={key:0},D={class:"top-bar-right"},L={class:"trial-modal-content"},N={class:"modal-main"},z={class:"left-panel"},F={key:0,class:"section dense-section"},B={key:0,class:"param-section"},q={key:5,class:"text-secondary text-xs"},V={key:6,class:"param-description text-secondary"},K={class:"param-section"},H={class:"response-mode-option-compact"},J={class:"mode-label"},G={class:"mode-desc"},Y={key:1,class:"param-section"},W={key:5,class:"text-secondary text-xs"},X={key:6,class:"param-description text-secondary"},Q={class:"param-section"},Z={class:"api-preview"},ee={class:"action-section"},te={class:"right-panel"},ae={class:"section dense-section"},ne={key:0,class:"cost-calculation-compact"},se={class:"cost-row"},re={key:0,class:"cost-total"},oe={class:"bottom-panel"},ie={class:"section dense-section"},le={key:1,class:"config-list-compact"},pe={class:"config-compact-left"},ce={class:"config-name"},ue={class:"config-model"},de={class:"config-compact-right"},me={key:2,class:"trial-summary-compact"},ve={class:"summary-row"},fe={class:"summary-item"},ge={class:"summary-item"},ye={class:"summary-item"},he={class:"text-primary"},_e={class:"summary-item"},be={class:"text-success"},xe={class:"modal-footer"},ke=d(v({__name:"TrialCreationModal",props:{trialToDuplicate:{}},emits:["close","created"],setup(i,{emit:d}){const v=i,ke=d,we=e(),Se=s(),Ae=r(),Te=o(),$e=p(),Ce=f(""),Pe=f(""),Ie=f(null),Ee=f({}),Re=f("text"),Oe=f([]),je=g(()=>we.designs),Me=g(()=>Ae.modelsByProvider),Ue=g(()=>je.value.find(e=>e.id===Pe.value)),De=g(()=>Ue.value?t.extractVariables(Ue.value.promptTemplate):[]),Le=g(()=>{if(!Ue.value?.variableBindings)return 0;let e=1;for(const[,t]of Object.entries(Ue.value.variableBindings))if("list"===t.type&&t.listId){const a=Se.lists.find(e=>e.id===t.listId);e*=a?.itemCount||0}else"direct"===t.type&&t.values&&(e*=t.values.length);return e}),Ne=g(()=>{const e=[];return Object.entries(Me.value).forEach(([,t])=>{const a=t.filter(e=>e.enabled);e.push(...a)}),e}),ze=g(()=>Ie.value?l.getBasicParameters(Ie.value.provider,Ie.value.modelId):{}),Fe=g(()=>Ie.value?l.getAdvancedParameters(Ie.value.provider,Ie.value.modelId):{}),Be=g(()=>Ie.value?l.getResponseModes(Ie.value.provider):{}),qe=g(()=>{if(!Ie.value)return"";try{const e=l.applyResponseMode(Ie.value.provider,Re.value,Ee.value),t=a.buildAPIRequest({id:"preview",name:"Preview",provider:Ie.value.provider,model:Ie.value.modelId,params:e,created_at:new Date},"{{prompt}}",$e.getApiKey(Ie.value.provider),$e.getBaseUrl(Ie.value.provider));return JSON.stringify(t.body,null,2)}catch(e){return"Error generating preview"}}),Ve=g(()=>Ce.value.trim().length>0),Ke=g(()=>""!==Pe.value),He=g(()=>null!==Ie.value),Je=g(()=>Le.value),Ge=g(()=>Oe.value.length*Je.value),Ye=g(()=>{let e=0;return Oe.value.forEach(t=>{const a=nt(t);a&&(e+=a*Je.value)}),e}),We=g(()=>Ve.value&&Ke.value&&Oe.value.length>0&&Le.value>0),Xe=g(()=>{if(!Ie.value)return null;const e=Ie.value;if(!e.capabilities?.inputCostPerToken||!e.capabilities?.outputCostPerToken)return null;return 100*e.capabilities.inputCostPerToken+50*e.capabilities.outputCostPerToken});function Qe(e,t){const a=Ee.value[e];if(a)try{const n=JSON.parse(a);if("array"===t&&!Array.isArray(n))throw new Error("Value must be an array");if("object"===t&&"object"!=typeof n)throw new Error("Value must be an object");Ee.value[e]=n}catch(n){console.error(`Invalid JSON for ${e}:`,n)}}function Ze(e){Ie.value=e,Ee.value={},Re.value="text";const t=l.getParametersForModel(e.provider,e.modelId);Object.entries(t).forEach(([e,t])=>{void 0!==t.default&&(Ee.value[e]=t.default)})}function et(){}function tt(){if(!Ie.value)return;const e=l.applyResponseMode(Ie.value.provider,Re.value,Ee.value),t=Be.value[Re.value]?.label||Re.value;Oe.value.push({name:`${Ie.value.displayName} (${t})`,provider:Ie.value.provider,modelId:Ie.value.modelId,parameters:{...e}}),Ie.value=null,Ee.value={},Re.value="text"}function at(e){Oe.value.splice(e,1)}function nt(e){const t=Ae.getModel(e.provider,e.modelId);if(!t?.capabilities?.inputCostPerToken||!t?.capabilities?.outputCostPerToken)return null;return 100*t.capabilities.inputCostPerToken+50*t.capabilities.outputCostPerToken}async function st(){try{const e=await Te.createTrial({name:Ce.value,designId:Pe.value,configurations:JSON.parse(JSON.stringify(Oe.value))});ke("created",e),ke("close")}catch(e){console.error("Failed to create trial:",e),alert("Failed to create trial: "+(e instanceof Error?e.message:"Unknown error"))}}return y(()=>v.trialToDuplicate,async e=>{if(e){console.log("Duplicating trial:",e),console.log("Trial keys:",Object.keys(e)),console.log("designSnapshot:",e.designSnapshot),Ce.value=`${e.name} (Copy)`,await we.initialize();const t=e.designSnapshot?.originalId;console.log("Setting design ID:",t),Pe.value=t,Oe.value=(e.configurationSnapshots||e.configurations||[]).map(e=>({...e,id:u()}))}},{immediate:!0}),y(Pe,async e=>{if(!e||Ce.value)return;const t=je.value.find(t=>t.id===e);if(!t)return;if(!t.tokenEstimate&&t.variableBindings&&Object.keys(t.variableBindings).length>0)try{const e=await n.calculateDesignTokens(t);await we.updateDesign(t.id,{tokenEstimate:e})}catch(i){console.warn("Failed to calculate token estimate:",i)}const a=Te.trials,s=t.name.toLowerCase(),r=new RegExp(`^${s}\\s+(\\d+)$`,"i");let o=0;for(const n of a){const e=n.name.match(r);if(e){const t=parseInt(e[1]);t>o&&(o=t)}}Ce.value=`${s} ${o+1}`}),h(async()=>{await we.initialize(),await Se.initialize(),await Te.initialize()}),(e,t)=>{const a=b("a-input"),n=b("a-select-option"),s=b("a-select"),r=b("a-tag"),o=b("a-input-number"),i=b("a-switch"),p=b("a-textarea"),u=b("a-form-item"),d=b("a-col"),v=b("a-row"),f=b("a-form"),g=b("a-collapse-panel"),y=b("a-collapse"),h=b("a-button"),ke=b("a-empty"),we=b("a-space"),Se=b("a-modal");return k(),_(Se,{open:!0,title:null,width:"95vw",style:{top:"5vh",maxWidth:"none"},bodyStyle:{height:"85vh",padding:"0",overflow:"hidden"},footer:null,maskClosable:!1,onCancel:t[5]||(t[5]=t=>e.$emit("close"))},{default:x(()=>[w("div",R,[w("div",O,[t[8]||(t[8]=w("span",{class:"create-trial-title"},"Create Trial",-1)),t[9]||(t[9]=w("span",{class:"top-bar-separator"},"|",-1)),S(a,{value:Ce.value,"onUpdate:value":t[0]||(t[0]=e=>Ce.value=e),placeholder:"Enter trial name...",size:"small",class:"trial-name-input",style:{width:"200px"}},null,8,["value"]),S(s,{value:Pe.value,"onUpdate:value":t[1]||(t[1]=e=>Pe.value=e),placeholder:"Select design...",size:"small",style:{width:"150px"},showSearch:"","filter-option":(e,t)=>(t?.label||t?.value||"").toLowerCase().includes(e.toLowerCase())},{default:x(()=>[(k(!0),A(C,null,$(je.value,e=>(k(),_(n,{key:e.id,value:e.id,label:e.name},{default:x(()=>[P(I(e.name),1)]),_:2},1032,["value","label"]))),128))]),_:1},8,["value","filter-option"]),Ue.value?(k(),A("span",j,[(k(!0),A(C,null,$(De.value,e=>(k(),_(r,{key:e,size:"small",color:"blue"},{default:x(()=>[P(I(e),1)]),_:2},1024))),128)),w("span",M,[P(" ("+I(Le.value)+" conditions",1),Ue.value?.tokenEstimate?(k(),A("span",U,[P(", ~"+I(Ue.value.tokenEstimate.avgTokens)+" tokens/prompt",1),t[6]||(t[6]=w("span",{class:"approx-indicator",title:"Approximated using 4 chars/token"},"*",-1))])):T("",!0),t[7]||(t[7]=P(") "))])])):T("",!0)]),w("div",D,[S(E(c),{onClick:t[2]||(t[2]=t=>e.$emit("close")),class:"close-icon"})])]),w("div",L,[w("div",N,[w("div",z,[Ie.value?(k(),A("div",F,[w("h3",null,"Configure: "+I(Ie.value.displayName),1),Object.keys(ze.value).length>0?(k(),A("div",B,[t[10]||(t[10]=w("h4",null,"Basic Parameters",-1)),S(f,{layout:"vertical",size:"small"},{default:x(()=>[S(v,{gutter:[8,8]},{default:x(()=>[(k(!0),A(C,null,$(ze.value,(e,t)=>(k(),_(d,{key:t,span:12},{default:x(()=>[S(u,{label:t,class:"dense-form-item"},{default:x(()=>["number"===e.type||"integer"===e.type?(k(),_(o,{key:0,value:Ee.value[t],"onUpdate:value":e=>Ee.value[t]=e,min:e.min,max:e.max,step:"integer"===e.type?1:.1,placeholder:String(e.default),size:"small",style:{width:"100%"}},null,8,["value","onUpdate:value","min","max","step","placeholder"])):"string"!==e.type||e.enum?"string"===e.type&&e.enum?(k(),_(s,{key:2,value:Ee.value[t],"onUpdate:value":e=>Ee.value[t]=e,size:"small"},{default:x(()=>[(k(!0),A(C,null,$(e.enum,e=>(k(),_(n,{key:e,value:e},{default:x(()=>[P(I(e),1)]),_:2},1032,["value"]))),128))]),_:2},1032,["value","onUpdate:value"])):"boolean"===e.type?(k(),_(i,{key:3,checked:Ee.value[t],"onUpdate:checked":e=>Ee.value[t]=e,size:"small"},null,8,["checked","onUpdate:checked"])):"array"===e.type||"object"===e.type?(k(),_(p,{key:4,value:Ee.value[t],"onUpdate:value":e=>Ee.value[t]=e,placeholder:"array"===e.type?"[...]":"{...}","auto-size":{minRows:1,maxRows:3},size:"small",onBlur:a=>Qe(t,e.type)},null,8,["value","onUpdate:value","placeholder","onBlur"])):(k(),A("span",q,I(e.type)+" not supported ",1)):(k(),_(a,{key:1,value:Ee.value[t],"onUpdate:value":e=>Ee.value[t]=e,placeholder:String(e.default),size:"small"},null,8,["value","onUpdate:value","placeholder"])),e.description?(k(),A("small",V,I(e.description),1)):T("",!0)]),_:2},1032,["label"])]),_:2},1024))),128))]),_:1})]),_:1})])):T("",!0),w("div",K,[t[11]||(t[11]=w("h4",null,"Response Mode",-1)),S(s,{value:Re.value,"onUpdate:value":t[3]||(t[3]=e=>Re.value=e),onChange:et,size:"small",style:{width:"100%"}},{default:x(()=>[(k(!0),A(C,null,$(Be.value,(e,t)=>(k(),_(n,{key:t,value:t},{default:x(()=>[w("div",H,[w("span",J,I(e.label),1),w("span",G,I(e.description),1)])]),_:2},1032,["value"]))),128))]),_:1},8,["value"])]),Object.keys(Fe.value).length>0?(k(),A("div",Y,[S(y,{size:"small",ghost:""},{default:x(()=>[S(g,{key:"advanced",header:"Advanced Parameters"},{default:x(()=>[S(f,{layout:"vertical",size:"small"},{default:x(()=>[S(v,{gutter:[8,8]},{default:x(()=>[(k(!0),A(C,null,$(Fe.value,(e,t)=>(k(),_(d,{key:t,span:12},{default:x(()=>[S(u,{label:t,class:"dense-form-item"},{default:x(()=>["number"===e.type||"integer"===e.type?(k(),_(o,{key:0,value:Ee.value[t],"onUpdate:value":e=>Ee.value[t]=e,min:e.min,max:e.max,step:"integer"===e.type?1:.1,placeholder:String(e.default),size:"small",style:{width:"100%"}},null,8,["value","onUpdate:value","min","max","step","placeholder"])):"string"!==e.type||e.enum?"string"===e.type&&e.enum?(k(),_(s,{key:2,value:Ee.value[t],"onUpdate:value":e=>Ee.value[t]=e,size:"small"},{default:x(()=>[(k(!0),A(C,null,$(e.enum,e=>(k(),_(n,{key:e,value:e},{default:x(()=>[P(I(e),1)]),_:2},1032,["value"]))),128))]),_:2},1032,["value","onUpdate:value"])):"boolean"===e.type?(k(),_(i,{key:3,checked:Ee.value[t],"onUpdate:checked":e=>Ee.value[t]=e,size:"small"},null,8,["checked","onUpdate:checked"])):"array"===e.type||"object"===e.type?(k(),_(p,{key:4,value:Ee.value[t],"onUpdate:value":e=>Ee.value[t]=e,placeholder:"array"===e.type?"[...]":"{...}","auto-size":{minRows:1,maxRows:3},size:"small",onBlur:a=>Qe(t,e.type)},null,8,["value","onUpdate:value","placeholder","onBlur"])):(k(),A("span",W,I(e.type)+" not supported ",1)):(k(),_(a,{key:1,value:Ee.value[t],"onUpdate:value":e=>Ee.value[t]=e,placeholder:String(e.default),size:"small"},null,8,["value","onUpdate:value","placeholder"])),e.description?(k(),A("small",X,I(e.description),1)):T("",!0)]),_:2},1032,["label"])]),_:2},1024))),128))]),_:1})]),_:1})]),_:1})]),_:1})])):T("",!0),w("div",Q,[S(y,{size:"small",ghost:""},{default:x(()=>[S(g,{key:"preview",header:"Raw API Preview"},{default:x(()=>[w("pre",Z,I(qe.value),1)]),_:1})]),_:1})]),w("div",ee,[S(h,{type:"primary",onClick:tt,disabled:!He.value,size:"small",block:""},{default:x(()=>t[12]||(t[12]=[P(" Add Configuration ")])),_:1,__:[12]},8,["disabled"])])])):T("",!0)]),w("div",te,[w("div",ae,[t[15]||(t[15]=w("h3",null,"Select Model",-1)),Ie.value&&Xe.value?(k(),A("div",ne,[w("div",se,[t[14]||(t[14]=w("span",{class:"cost-label"},"Cost per call:",-1)),w("strong",null,"$"+I(Xe.value.toFixed(5)),1),Je.value>0?(k(),A("span",re,[t[13]||(t[13]=P(" • Total: ")),w("strong",null,"$"+I((Xe.value*Je.value).toFixed(3)),1),P(" ("+I(Je.value)+" calls) ",1)])):T("",!0)])])):T("",!0),S(m,{models:Ne.value,"selected-model":Ie.value,"is-loading":!1,"total-calls":Le.value,design:Ue.value,"model-params":Ee.value,onModelSelected:Ze,onModelConfigured:Ze},null,8,["models","selected-model","total-calls","design","model-params"])])])]),w("div",oe,[w("div",ie,[t[23]||(t[23]=w("h3",null,"Trial Configurations",-1)),0===Oe.value.length?(k(),_(ke,{key:0,description:"No configurations added yet. Select a model and configure parameters.",style:{margin:"var(--spacing-md) 0"}},{image:x(()=>t[16]||(t[16]=[w("div",{style:{color:"var(--color-text-disabled)","font-size":"var(--font-size-xxl)"}},"⚙️",-1)])),_:1})):(k(),A("div",le,[(k(!0),A(C,null,$(Oe.value,(e,a)=>(k(),A("div",{key:a,class:"config-item-compact"},[w("div",pe,[w("strong",ce,I(e.name),1),w("span",ue,I(e.provider)+":"+I(e.modelId),1),S(r,{size:"small",color:"green"},{default:x(()=>[P("$"+I(nt(e)?.toFixed(4)),1)]),_:2},1024)]),w("div",de,[S(h,{type:"text",size:"small",onClick:e=>function(e){const t=Oe.value[e],a=Ae.getModel(t.provider,t.modelId);if(a){Ie.value=a,Ee.value={...t.parameters};const e=l.getResponseModes(t.provider);Re.value="text";for(const[a,n]of Object.entries(e)){const e=n.parameters||{};if(Object.keys(e).every(e=>e in t.parameters)&&Object.keys(e).length>0){Re.value=a;break}}}at(e)}(a)},{default:x(()=>t[17]||(t[17]=[P("Edit")])),_:2,__:[17]},1032,["onClick"]),S(h,{type:"text",size:"small",danger:"",onClick:e=>at(a)},{default:x(()=>t[18]||(t[18]=[P("Remove")])),_:2,__:[18]},1032,["onClick"])])]))),128))])),Oe.value.length>0&&Le.value>0?(k(),A("div",me,[w("div",ve,[w("div",fe,[t[19]||(t[19]=w("span",{class:"summary-label"},"Variables:",-1)),w("strong",null,I(Je.value),1)]),w("div",ge,[t[20]||(t[20]=w("span",{class:"summary-label"},"Configs:",-1)),w("strong",null,I(Oe.value.length),1)]),w("div",ye,[t[21]||(t[21]=w("span",{class:"summary-label"},"Total Calls:",-1)),w("strong",he,I(Ge.value),1)]),w("div",_e,[t[22]||(t[22]=w("span",{class:"summary-label"},"Cost:",-1)),w("strong",be,"$"+I(Ye.value.toFixed(2)),1)])])])):T("",!0)])]),w("div",xe,[S(we,null,{default:x(()=>[S(h,{onClick:t[4]||(t[4]=t=>e.$emit("close")),size:"small"},{default:x(()=>t[24]||(t[24]=[P(" Cancel ")])),_:1,__:[24]}),S(h,{type:"primary",onClick:st,disabled:!We.value,size:"small"},{default:x(()=>t[25]||(t[25]=[P(" Create Trial ")])),_:1,__:[25]},8,["disabled"])]),_:1})])])]),_:1})}}}),[["__scopeId","data-v-928e6c16"]]),we={class:"trial-overview"},Se={class:"overview-section"},Ae={class:"cost-value"},Te={class:"overview-section"},$e={class:"progress-details"},Ce={class:"progress-stats"},Pe={class:"configurations-section"},Ie={key:0,class:"model-info"},Ee={key:0},Re={class:"prompt-section"},Oe={key:0,class:"variables-section"},je=v({__name:"TrialDetailModal",props:{trial:{}},emits:["close","updated"],setup(e){const t=e,a=[{title:"Model",key:"model",width:200},{title:"Parameters",key:"params",width:300},{title:"Cost/Call",key:"cost",width:100,align:"right"}],n=g(()=>0===t.trial.progress.total?0:Math.round(t.trial.progress.completed/t.trial.progress.total*100));function s(e){const t=Object.entries(e).map(([e,t])=>`${e}: ${t}`).join(", ");return t.length>50?t.substring(0,50)+"...":t}function r(){const e=t.trial.variableSnapshots;return e&&0!==e.length?e.map(e=>({variable:e.variableName,listName:e.originalListName,count:e.data.itemCount})):[]}return(e,t)=>{const o=b("a-button"),i=b("a-tag"),l=b("a-descriptions-item"),p=b("a-descriptions"),c=b("a-progress"),u=b("a-typography-text"),d=b("a-table"),m=b("a-typography-paragraph"),v=b("a-list-item-meta"),f=b("a-list-item"),g=b("a-list"),y=b("a-modal");return k(),_(y,{open:!0,title:e.trial.name,width:"95vw",centered:!0,onCancel:t[1]||(t[1]=t=>e.$emit("close")),"wrap-class-name":"trial-detail-modal","body-style":{height:"90vh",overflow:"auto"}},{footer:x(()=>[S(o,{onClick:t[0]||(t[0]=t=>e.$emit("close"))},{default:x(()=>t[2]||(t[2]=[P("Close")])),_:1,__:[2]})]),default:x(()=>[w("div",we,[w("div",Se,[t[3]||(t[3]=w("h3",null,"Trial Information",-1)),S(p,{column:2,size:"small",bordered:""},{default:x(()=>[S(l,{label:"Status"},{default:x(()=>{return[S(i,{color:(t=e.trial.status,{completed:"success",failed:"error",running:"processing",cancelled:"default",draft:"default",pending:"processing",paused:"warning"}[t]||"default")},{default:x(()=>[P(I(e.trial.status.toUpperCase()),1)]),_:1},8,["color"])];var t}),_:1}),S(l,{label:"Design"},{default:x(()=>[P(I(e.trial.designSnapshot.originalName),1)]),_:1}),S(l,{label:"Created"},{default:x(()=>{return[P(I((t=e.trial.created,new Date(t).toLocaleString())),1)];var t}),_:1}),S(l,{label:"Estimated Cost"},{default:x(()=>[w("span",Ae,"$"+I(e.trial.estimatedCost.toFixed(3)),1)]),_:1})]),_:1})]),w("div",Te,[t[4]||(t[4]=w("h3",null,"Progress",-1)),w("div",$e,[S(c,{percent:n.value,status:"failed"===e.trial.status?"exception":"active",size:"small"},null,8,["percent","status"]),w("div",Ce,[S(i,null,{default:x(()=>[P(I(e.trial.progress.completed)+" / "+I(e.trial.progress.total)+" completed",1)]),_:1}),e.trial.progress.networkErrors>0?(k(),_(i,{key:0,color:"error"},{default:x(()=>[P(I(e.trial.progress.networkErrors)+" network errors ",1)]),_:1})):T("",!0)])])])]),w("div",Pe,[w("h3",null,"Configurations ("+I(e.trial.configurationSnapshots.length)+")",1),S(d,{columns:a,"data-source":e.trial.configurationSnapshots,pagination:!1,size:"small",scroll:{y:300},"row-key":"id"},{bodyCell:x(({column:e,record:t})=>["model"===e.key?(k(),A("div",Ie,[w("strong",null,I(t.provider),1),w("small",null,I(t.modelId),1)])):T("",!0),"params"===e.key?(k(),_(u,{key:1,code:"",class:"params-preview"},{default:x(()=>[P(I(s(t.parameters)),1)]),_:2},1024)):T("",!0),"cost"===e.key?(k(),A(C,{key:2},[(k(),A("span",Ee," $"+I(.001.toFixed(4)),1))],64)):T("",!0)]),_:1},8,["data-source"])]),w("div",Re,[t[5]||(t[5]=w("h3",null,"Prompt Template",-1)),S(m,{code:"",class:"prompt-template"},{default:x(()=>[P(I(e.trial.designSnapshot.promptTemplate),1)]),_:1})]),e.trial.variableSnapshots?.length?(k(),A("div",Oe,[t[6]||(t[6]=w("h3",null,"Variables",-1)),S(g,{"data-source":r(),size:"small",split:!1},{renderItem:x(({item:e})=>[S(f,null,{default:x(()=>[S(v,null,{title:x(()=>[S(i,{color:"blue"},{default:x(()=>[P(I(e.variable),1)]),_:2},1024)]),description:x(()=>[w("span",null,I(e.listName)+" ("+I(e.count)+" values)",1)]),_:2},1024)]),_:2},1024)]),_:1},8,["data-source"])])):T("",!0)]),_:1},8,["title"])}}});class Me{static extractTrialData(e){const t=new i({getApiKey:()=>{},getBaseUrl:()=>{}}).generateVariableCombinations(e),a=new Set(e.configurationSnapshots.map(e=>e.provider)),n={};for(const o of a){const e=l.getProvider(o);e&&(n[o]={id:e.id,name:e.name,api:e.api,auth:e.auth,headers:e.headers,requestTransform:e.requestTransform,responseModes:e.responseModes||{}})}const s=e.configurationSnapshots.map(e=>{const t=l.getProvider(e.provider),a=this.detectResponseMode(e,t);return{id:`${e.provider}:${e.modelId}`,name:e.name,provider:e.provider,model:e.modelId,parameters:e.parameters,responseMode:a}}),r=[];for(let o=0;o<s.length;o++)for(const a of t){let t=e.designSnapshot.promptTemplate;Object.entries(a.variables).forEach(([e,a])=>{const n=`{{${e}}}`;t=t.replace(new RegExp(n,"g"),a)}),r.push({id:`${o}-${JSON.stringify(a.variables)}`,configurationId:s[o].id,variables:a.variables,prompt:t})}return{metadata:{exportedAt:(new Date).toISOString(),trialName:e.name||`Trial ${e.id}`,trialId:e.id},experiment:{design:{name:e.designSnapshot.originalName,promptTemplate:e.designSnapshot.promptTemplate,outputType:e.designSnapshot.outputType||"text",extractPattern:e.designSnapshot.extractPattern,refusalWords:e.designSnapshot.refusalWords},variableCombinations:t.map(e=>e.variables),configurations:s},providers:n,apiCalls:r}}static detectResponseMode(e,t){if(!t?.responseModes)return{id:"text",label:"Text",parameters:{},responseTransform:{contentPath:"content",fallbackPaths:["response","text"]}};for(const[n,s]of Object.entries(t.responseModes)){const t=s.parameters||{};if(Object.keys(t).every(t=>t in e.parameters)&&Object.keys(t).length>0)return{id:n,label:s.label||n,parameters:t,responseTransform:s.responseTransform}}const a=t.responseModes.text||Object.values(t.responseModes)[0];return{id:"text",label:a?.label||"Text",parameters:a?.parameters||{},responseTransform:a?.responseTransform||{contentPath:"content",fallbackPaths:["response","text"]}}}}class Ue{static generateProviderFunctions(e){const t=[];for(const[a,n]of Object.entries(e.providers)){const e=this.generateProviderFunction(a,n);t.push(e)}return t.join("\n\n")}static generateProviderFunction(e,t){const a=this.getFunctionName(e),n=t.api.endpoints.chat||t.api.endpoints.generate,s=`${t.api.baseUrl}${n}`;return`def ${a}(prompt: str, model: str, params: Dict[str, Any], api_key: Optional[str], provider_config: Dict[str, Any]) -> Dict[str, Any]:\n    """\n    Call ${t.name} API\n    Mirrors ParameterAdapter.buildAPIRequest() logic for ${e}\n    """\n    ${this.generateHeadersCode(t)}\n    \n    ${this.generateRequestBodyCode(e,t)}\n    \n    # Make API request\n    start_time = time.time()\n    \n    try:\n        response = requests.post(\n            "${s}",\n            headers=headers,\n            json=payload,\n            timeout=TIMEOUT\n        )\n        \n        latency_ms = (time.time() - start_time) * 1000\n        \n        # Build response object (matches APIResponse schema)\n        return {\n            'status': response.status_code,\n            'headers': dict(response.headers),\n            'body': response.json() if response.ok else response.text,\n            'latency_ms': latency_ms\n        }\n    \n    except requests.exceptions.RequestException as e:\n        latency_ms = (time.time() - start_time) * 1000\n        return {\n            'status': 0,\n            'headers': {},\n            'body': {'error': str(e)},\n            'latency_ms': latency_ms\n        }`}static generateHeadersCode(e){const t=[];if(t.push("# Build headers (mirrors ParameterAdapter.buildHeaders)"),t.push("headers = {"),t.push('    "Content-Type": "application/json"'),e.headers)for(const[a,n]of Object.entries(e.headers))t.push(`    "${a}": "${n}",`);return t.push("}"),t.push(""),"bearer"===e.auth.type?(t.push("# Add authentication"),t.push("if api_key:"),t.push('    headers["Authorization"] = f"Bearer {api_key}"')):"header"===e.auth.type&&e.auth.header&&(t.push("# Add authentication"),t.push("if api_key:"),t.push(`    headers["${e.auth.header}"] = api_key`)),t.map(e=>e?"    "+e:"").join("\n")}static generateRequestBodyCode(e,t){const a=[],n=t.requestTransform;if(a.push("# Build request body (mirrors ParameterAdapter.buildRequestBody)"),a.push("# Strip provider prefix from model name"),a.push(`model_name = model[${e.length+1}:] if model.startswith("${e}:") else model`),a.push(""),a.push("payload = {"),a.push('    "model": model_name'),a.push("}"),a.push(""),n?.promptKey){if(a.push("# Handle prompt formatting"),n.wrapPrompt){const e=n.messageRole||"user";a.push(`payload["${n.promptKey}"] = [{`),a.push(`    "role": "${e}",`),a.push('    "content": prompt'),a.push("}]")}else a.push(`payload["${n.promptKey}"] = prompt`);a.push("")}n?.nestParams?(a.push("# Handle parameter nesting"),a.push(`payload["${n.nestParams}"] = params`)):(a.push("# Spread parameters directly into payload"),a.push("payload.update(params)")),a.push("");const s=this.generateProviderSpecificTransforms(e);return s&&(a.push("# Provider-specific transformations"),a.push(s)),a.map(e=>e?"    "+e:"").join("\n")}static generateProviderSpecificTransforms(e){switch(e){case"openai-chat":return'# Handle response_format for OpenAI\nif "response_format" in payload and isinstance(payload["response_format"], str):\n    payload["response_format"] = {"type": payload["response_format"]}';case"openai-responses":return'# Responses API uses \'input\' instead of \'messages\'\nif "messages" in payload:\n    payload["input"] = payload["messages"][0]["content"]\n    del payload["messages"]';case"anthropic":return'# Anthropic requires max_tokens at root level\nif "messages" in payload and "max_tokens" not in payload:\n    raise ValueError("Anthropic requires max_tokens parameter")';case"ollama-generate":return"# Ollama generate uses 'prompt' directly, not wrapped\n# Already handled by requestTransform";case"openrouter":return"# OpenRouter supports additional routing parameters\n# These are already in the params, no transform needed";default:return""}}static getFunctionName(e){return`call_${e.replace("-","_")}`}}class De{static async generatePythonScript(e,t){try{const a=t||this.getDefaultOptions(),n=Me.extractTrialData(e);switch(a.mode){case"literal":return this.generateLiteralScript(n,a);case"hydrated":return this.generateHydratedScript(n,a);case"minimal":return this.generateMinimalScript(n,a);default:throw new Error(`Unknown export mode: ${a.mode}`)}}catch(a){throw new Error(`Failed to generate Python export: ${a instanceof Error?a.message:String(a)}`)}}static async downloadPythonScript(e,t){const a=await this.generatePythonScript(e,t),n=t||this.getDefaultOptions(),s=new Blob([a],{type:"text/x-python"}),r=URL.createObjectURL(s),o=document.createElement("a");o.href=r,o.download=this.generateFilename(e,n.mode),document.body.appendChild(o),o.click(),document.body.removeChild(o),URL.revokeObjectURL(r)}static validateTrialForExport(e){const t=[];return e.designSnapshot?e.designSnapshot.promptTemplate||t.push("Design missing prompt template"):t.push("Trial missing design snapshot"),e.configurationSnapshots&&0!==e.configurationSnapshots.length?e.configurationSnapshots.forEach((e,a)=>{e.provider||t.push(`Configuration ${a+1} missing provider`),e.modelId||t.push(`Configuration ${a+1} missing model`),e.parameters||t.push(`Configuration ${a+1} missing parameters`)}):t.push("Trial missing model configurations"),e.variableSnapshots||t.push("Trial missing variable snapshots"),{valid:0===t.length,errors:t}}static getExportSummary(e){const t=Me.extractTrialData(e);return{apiCallCount:t.apiCalls.length,providersUsed:Object.keys(t.providers),variableCombinations:t.experiment.variableCombinations.length,configurations:t.experiment.configurations.length}}static generateLiteralScript(e,t){const a=this.generateImports(t),n=this.generateConstants(t),s=JSON.stringify(e.apiCalls,null,2);return`#!/usr/bin/env python3\n"""\nTrial Reproduction Script (Literal Mode)\nGenerated by Auditomatic Lite on ${e.metadata.exportedAt}\n\nThis script contains pre-computed API calls for maximum reproducibility.\nAll prompts and parameters are stored as data - just run and compare results.\n"""\n\n${a}\n\n# Configuration\n${n}\n\n# Pre-computed API calls\nAPI_CALLS = ${s}\n\n# Provider configurations  \nPROVIDERS = ${JSON.stringify(e.providers,null,2)}\n\n${this.generateLiteralExecutionFunctions(t)}\n\ndef main():\n    print(f"Reproducing trial: ${e.metadata.trialName}")\n    print(f"Mode: Literal (pre-computed calls)")\n    print(f"Total calls: {exportData.apiCalls.length}")\n    print("=" * 60)\n    \n    results = execute_literal_calls(API_CALLS, PROVIDERS)\n    \n    ${this.generateResultsOutput(t)}\n\nif __name__ == "__main__":\n    main()\n`}static generateHydratedScript(e,t){const a=this.generateImports(t),n=this.generateConstants(t),s=Ue.generateProviderFunctions(e);return`#!/usr/bin/env python3\n"""\nTrial Reproduction Script (Hydrated Mode)  \nGenerated by Auditomatic Lite on ${e.metadata.exportedAt}\n\nThis script regenerates API calls from the original prompt template and variables.\nMatches the exact logic used in your trial execution.\n"""\n\n${a}\n\n# Configuration\n${n}\n\n# Experiment definition\nEXPERIMENT = ${JSON.stringify(e.experiment,null,2)}\n\n# Provider configurations\nPROVIDERS = ${JSON.stringify(e.providers,null,2)}\n\n${s}\n\n${this.generateHydratedExecutionFunctions(t)}\n\ndef main():\n    print(f"Reproducing trial: ${e.metadata.trialName}")\n    print(f"Mode: Hydrated (template-driven)")\n    print(f"Configurations: {exportData.experiment.configurations.length}")\n    print(f"Variable combinations: {exportData.experiment.variableCombinations.length}")\n    print(f"Total calls: {exportData.experiment.configurations.length * exportData.experiment.variableCombinations.length}")\n    print("=" * 60)\n    \n    results = execute_hydrated_experiment(EXPERIMENT, PROVIDERS)\n    \n    ${this.generateResultsOutput(t)}\n\nif __name__ == "__main__":\n    main()\n`}static generateMinimalScript(e,t){const a=Object.keys(e.providers),n=e.experiment.design.promptTemplate.replace(/\{\{(\w+)\}\}/g,"{$1}"),s=e.experiment.variableCombinations.map(e=>JSON.stringify(e)).join(",\n    "),r=e.experiment.configurations.map(t=>{const a=e.providers[t.provider];return`    "${t.name}": {\n        "provider": "${t.provider}",\n        "model": "${t.model}",\n        "url": "${a.api.baseUrl}${a.api.endpoints.chat||a.api.endpoints.generate}",\n        "params": ${JSON.stringify(t.parameters,null,8).split("\n").map((e,t)=>0===t?e:"        "+e).join("\n")}\n    }`}).join(",\n"),o=this.generateProviderFunctions(a,e.providers);return`#!/usr/bin/env python3\n"""\nMinimal Trial Reproduction Script\nGenerated by Auditomatic Lite on ${e.metadata.exportedAt}\n\nTrial: ${e.metadata.trialName}\nConfigurations: ${e.experiment.configurations.length}\nVariables: ${e.experiment.variableCombinations.length} combinations\nTotal API calls: ${e.experiment.configurations.length*e.experiment.variableCombinations.length}\n"""\n\nimport json\nimport os\nimport requests\nimport time\nfrom typing import Dict, List, Any\n\n# =============================================================================\n# EXPERIMENT DESIGN\n# =============================================================================\n\n# Your prompt template with {variable} placeholders\nPROMPT_TEMPLATE = "${n}"\n\n# Variable combinations to test\nVARIABLES = [\n    ${s}\n]\n\n# Model configurations\nCONFIGURATIONS = {\n${r}\n}\n\n# API Keys - set these before running!\nAPI_KEYS = {\n${a.map(e=>`    "${e}": os.environ.get("${e.toUpperCase().replace("-","_")}_API_KEY", ""),`).join("\n")}\n}\n\n# =============================================================================\n# PROVIDER-SPECIFIC FUNCTIONS\n# =============================================================================\n\n${o}\n\n# =============================================================================\n# MAIN EXECUTION\n# =============================================================================\n\ndef execute_trial():\n    """Execute all combinations of configurations and variables"""\n    results = []\n    total = len(CONFIGURATIONS) * len(VARIABLES)\n    count = 0\n    \n    print(f"Executing {total} API calls...")\n    print(f"Configurations: {list(CONFIGURATIONS.keys())}")\n    print(f"Variables: {len(VARIABLES)} combinations\\n")\n    \n    for config_name, config in CONFIGURATIONS.items():\n        for variables in VARIABLES:\n            count += 1\n            \n            # Format prompt with variables\n            prompt = PROMPT_TEMPLATE.format(**variables)\n            \n            # Show progress\n            var_str = ", ".join(f"{k}={v}" for k, v in variables.items())\n            print(f"[{count}/{total}] {config_name} with {var_str}", end=" ... ")\n            \n            # Make API call\n            start_time = time.time()\n            try:\n                response = call_provider(\n                    config["provider"],\n                    config["url"],\n                    prompt,\n                    config["model"],\n                    config["params"],\n                    API_KEYS.get(config["provider"])\n                )\n                latency_ms = (time.time() - start_time) * 1000\n                \n                # Extract content based on provider\n                content = extract_content(config["provider"], response)\n                \n                result = {\n                    "config": config_name,\n                    "variables": variables,\n                    "prompt": prompt,\n                    "response": content,\n                    "latency_ms": latency_ms,\n                    "success": True\n                }\n                print(f"✓ {latency_ms:.0f}ms")\n                \n            except Exception as e:\n                result = {\n                    "config": config_name,\n                    "variables": variables,\n                    "prompt": prompt,\n                    "error": str(e),\n                    "success": False\n                }\n                print(f"✗ {str(e)}")\n            \n            results.append(result)\n            \n            # Basic rate limiting\n            time.sleep(0.5)\n    \n    return results\n\ndef save_results(results: List[Dict[str, Any]]):\n    """Save results in multiple formats"""\n    \n    # Save as JSON\n    with open("trial_results.json", "w") as f:\n        json.dump(results, f, indent=2)\n    print("\\nResults saved to trial_results.json")\n    \n    # Save as CSV for analysis\n    import csv\n    with open("trial_results.csv", "w", newline="") as f:\n        if results:\n            # Get all variable names\n            var_names = list(results[0]["variables"].keys()) if results[0]["variables"] else []\n            fieldnames = ["config", "success", "latency_ms", "response"] + var_names\n            \n            writer = csv.DictWriter(f, fieldnames=fieldnames)\n            writer.writeheader()\n            \n            for result in results:\n                row = {\n                    "config": result["config"],\n                    "success": result.get("success", False),\n                    "latency_ms": result.get("latency_ms", ""),\n                    "response": result.get("response", result.get("error", ""))[:200]\n                }\n                # Add variable values\n                for var in var_names:\n                    row[var] = result["variables"].get(var, "")\n                writer.writerow(row)\n    \n    print("Results saved to trial_results.csv")\n\ndef analyze_results(results: List[Dict[str, Any]]):\n    """Basic analysis of results"""\n    \n    print("\\n" + "="*60)\n    print("RESULTS SUMMARY")\n    print("="*60)\n    \n    # Success rate by configuration\n    by_config = {}\n    for r in results:\n        config = r["config"]\n        if config not in by_config:\n            by_config[config] = {"success": 0, "total": 0, "latencies": []}\n        by_config[config]["total"] += 1\n        if r.get("success"):\n            by_config[config]["success"] += 1\n            by_config[config]["latencies"].append(r["latency_ms"])\n    \n    for config, stats in by_config.items():\n        success_rate = stats["success"] / stats["total"] * 100\n        avg_latency = sum(stats["latencies"]) / len(stats["latencies"]) if stats["latencies"] else 0\n        print(f"\\n{config}:")\n        print(f"  Success rate: {success_rate:.1f}% ({stats['success']}/{stats['total']})")\n        if stats["latencies"]:\n            print(f"  Avg latency: {avg_latency:.0f}ms")\n\nif __name__ == "__main__":\n    # Check for API keys\n    missing_keys = [p for p in set(c["provider"] for c in CONFIGURATIONS.values()) \n                    if not API_KEYS.get(p)]\n    if missing_keys:\n        print("WARNING: Missing API keys for:", ", ".join(missing_keys))\n        print("Set them in the API_KEYS dictionary above.\\n")\n        input("Press Enter to continue anyway, or Ctrl+C to exit...")\n    \n    # Run the trial\n    results = execute_trial()\n    \n    # Save and analyze\n    save_results(results)\n    analyze_results(results)\n`}static getDefaultOptions(){return{mode:"hydrated",options:{includeResults:!1,includeTiming:!0,includeErrorHandling:!0,parallelExecution:!1,rateLimit:!1,csvOutput:!1},advanced:{timeout:30,rateLimit:2,maxConcurrent:5,outputFormat:"console"}}}static generateFilename(e,t){const a=e.name||`trial_${e.id}`,n=(new Date).toISOString().split("T")[0];return`${a.toLowerCase().replace(/[^a-z0-9]/g,"_")}_${t}_${n}.py`}static generateImports(e){const t=["import os","import json","import requests","import time","from typing import Dict, Any, List, Optional"];return e.options.parallelExecution&&t.push("import asyncio","import aiohttp"),e.options.csvOutput&&t.push("import csv"),t.join("\n")}static generateConstants(e){return`TIMEOUT = ${e.advanced.timeout}\nRATE_LIMIT = ${e.advanced.rateLimit}\nMAX_CONCURRENT = ${e.advanced.maxConcurrent}\nOUTPUT_FORMAT = "${e.advanced.outputFormat}"`}static generateLiteralExecutionFunctions(e){return`\ndef execute_literal_calls(api_calls: List[Dict[str, Any]], providers: Dict[str, Any]) -> List[Dict[str, Any]]:\n    """Execute pre-computed API calls"""\n    results = []\n    \n    for i, call in enumerate(api_calls):\n        print(f"Executing call {i+1}/{len(api_calls)}: {call['configurationId']}")\n        \n        # Extract configuration\n        config_id = call['configurationId']\n        provider_id = config_id.split(':')[0]\n        \n        if provider_id not in providers:\n            print(f"Warning: Provider {provider_id} not configured")\n            continue\n            \n        # Make API call with stored prompt and parameters\n        result = make_api_call(\n            provider_id,\n            call['prompt'],\n            call.get('model', config_id),\n            call.get('parameters', {}),\n            providers[provider_id]\n        )\n        \n        result['call_id'] = call['id']\n        result['variables'] = call.get('variables', {})\n        results.append(result)\n        \n        ${e.options.rateLimit?"time.sleep(1 / RATE_LIMIT)":""}\n        \n    return results\n\ndef make_api_call(provider_id: str, prompt: str, model: str, params: Dict[str, Any], provider_config: Dict[str, Any]) -> Dict[str, Any]:\n    """Make API call to specific provider"""\n    api_key = os.environ.get(f"{provider_id.upper().replace('-', '_')}_API_KEY", "")\n    \n    # Build request\n    headers = {"Content-Type": "application/json"}\n    if provider_config['auth']['type'] == 'bearer':\n        headers['Authorization'] = f"Bearer {api_key}"\n    \n    # Build payload based on provider\n    payload = {"model": model.split(':')[-1]}\n    \n    if provider_config.get('requestTransform', {}).get('wrapPrompt'):\n        payload['messages'] = [{"role": "user", "content": prompt}]\n    else:\n        payload[provider_config.get('requestTransform', {}).get('promptKey', 'prompt')] = prompt\n    \n    payload.update(params)\n    \n    # Make request\n    url = provider_config['api']['baseUrl'] + provider_config['api']['endpoints']['chat']\n    \n    try:\n        start_time = time.time()\n        response = requests.post(url, headers=headers, json=payload, timeout=TIMEOUT)\n        latency = (time.time() - start_time) * 1000\n        \n        return {\n            'success': response.ok,\n            'status': response.status_code,\n            'latency_ms': latency,\n            'response': response.json() if response.ok else response.text,\n            'model': model,\n            'prompt': prompt\n        }\n    except Exception as e:\n        return {\n            'success': False,\n            'error': str(e),\n            'model': model,\n            'prompt': prompt\n        }\n`}static generateHydratedExecutionFunctions(e){return`\ndef execute_hydrated_experiment(experiment: Dict[str, Any], providers: Dict[str, Any]) -> List[Dict[str, Any]]:\n    """Execute experiment by hydrating template with variables"""\n    results = []\n    design = experiment['design']\n    \n    total_calls = len(experiment['configurations']) * len(experiment['variableCombinations'])\n    call_count = 0\n    \n    for config in experiment['configurations']:\n        for variables in experiment['variableCombinations']:\n            call_count += 1\n            print(f"Executing call {call_count}/{total_calls}: {config['name']}")\n            \n            # Hydrate prompt template\n            prompt = hydrate_template(design['promptTemplate'], variables)\n            \n            # Make API call\n            result = make_api_call(\n                config['provider'],\n                prompt,\n                config['model'],\n                config['parameters'],\n                providers[config['provider']]\n            )\n            \n            result['configuration'] = config['name']\n            result['variables'] = variables\n            results.append(result)\n            \n            ${e.options.rateLimit?"time.sleep(1 / RATE_LIMIT)":""}\n            \n    return results\n\ndef hydrate_template(template: str, variables: Dict[str, str]) -> str:\n    """Replace {{variable}} placeholders with actual values"""\n    result = template\n    for key, value in variables.items():\n        result = result.replace(f"{{{{{key}}}}}", str(value))\n    return result\n\ndef make_api_call(provider_id: str, prompt: str, model: str, params: Dict[str, Any], provider_config: Dict[str, Any]) -> Dict[str, Any]:\n    """Make API call to specific provider"""\n    api_key = os.environ.get(f"{provider_id.upper().replace('-', '_')}_API_KEY", "")\n    \n    # Build request\n    headers = {"Content-Type": "application/json"}\n    if provider_config['auth']['type'] == 'bearer':\n        headers['Authorization'] = f"Bearer {api_key}"\n    \n    # Build payload based on provider\n    payload = {"model": model.split(':')[-1]}\n    \n    if provider_config.get('requestTransform', {}).get('wrapPrompt'):\n        payload['messages'] = [{"role": "user", "content": prompt}]\n    else:\n        payload[provider_config.get('requestTransform', {}).get('promptKey', 'prompt')] = prompt\n    \n    payload.update(params)\n    \n    # Make request\n    url = provider_config['api']['baseUrl'] + provider_config['api']['endpoints']['chat']\n    \n    try:\n        start_time = time.time()\n        response = requests.post(url, headers=headers, json=payload, timeout=TIMEOUT)\n        latency = (time.time() - start_time) * 1000\n        \n        return {\n            'success': response.ok,\n            'status': response.status_code,\n            'latency_ms': latency,\n            'response': response.json() if response.ok else response.text,\n            'model': model,\n            'prompt': prompt\n        }\n    except Exception as e:\n        return {\n            'success': False,\n            'error': str(e),\n            'model': model,\n            'prompt': prompt\n        }\n`}static generateProviderFunctions(e,t){const a=[];a.push(`def call_provider(provider: str, url: str, prompt: str, model: str, params: Dict[str, Any], api_key: str) -> Any:\n    """Dispatch to provider-specific function"""\n    if not api_key:\n        raise ValueError(f"No API key provided for {provider}")\n    \n    # Call provider-specific function\n${e.map(e=>`    if provider == "${e}":\n        return call_${e.replace("-","_")}(url, prompt, model, params, api_key)`).join("\n")}\n    \n    raise ValueError(f"Unknown provider: {provider}")`);for(const n of e){const e=t[n];if(!e)continue;const s=`call_${n.replace("-","_")}`,r=e.auth;let o="";"bearer"===r.type?o='    headers["Authorization"] = f"Bearer {api_key}"':"header"===r.type&&r.header&&(o=`    headers["${r.header}"] = api_key`);let i="";const l=e.requestTransform;l?.promptKey&&(i=l.wrapPrompt?`    # Wrap in message format\n    body["${l.promptKey}"] = [{\n        "role": "${l.messageRole||"user"}",\n        "content": prompt\n    }]`:`    # Direct prompt\n    body["${l.promptKey}"] = prompt`);let p="";p=l?.nestParams?`    # Nest parameters\n    body["${l.nestParams}"] = params`:"    # Add parameters directly\n    body.update(params)";let c="";"openai-chat"!==n&&"openai-responses"!==n||(c='\n    # Handle response_format for OpenAI\n    if "response_format" in body and isinstance(body["response_format"], str):\n        body["response_format"] = {"type": body["response_format"]}'),"openai-responses"===n&&(c+='\n    \n    # Responses API uses \'input\' instead of \'messages\'\n    if "messages" in body:\n        body["input"] = body["messages"][0]["content"]\n        del body["messages"]'),a.push(`\ndef ${s}(url: str, prompt: str, model: str, params: Dict[str, Any], api_key: str) -> Any:\n    """Call ${e.name} API"""\n    \n    headers = {"Content-Type": "application/json"}\n${o}\n    \n    # Build request body\n    body = {"model": model}\n${i}\n${p}${c}\n    \n    # Make request\n    response = requests.post(url, headers=headers, json=body, timeout=30)\n    response.raise_for_status()\n    return response.json()`)}return a.push(`\ndef extract_content(provider: str, response: Any) -> str:\n    """Extract text content from provider-specific response format"""\n    \n    if not response or not isinstance(response, dict):\n        return str(response)\n    \n${e.map(e=>"openai-chat"===e||"openrouter"===e?`    if provider == "${e}":\n        return response.get("choices", [{}])[0].get("message", {}).get("content", "")`:"openai-responses"===e?`    if provider == "${e}":\n        output = response.get("output", [{}])[0]\n        if output.get("type") == "message":\n            content = output.get("content", [{}])[0]\n            if content.get("type") == "output_text":\n                return content.get("text", "")\n        return ""`:"anthropic"===e?`    if provider == "${e}":\n        content = response.get("content", [{}])[0]\n        return content.get("text", "") if content.get("type") == "text" else ""`:"ollama-chat"===e?`    if provider == "${e}":\n        return response.get("message", {}).get("content", "")`:"ollama-generate"===e?`    if provider == "${e}":\n        return response.get("response", "")`:"").filter(Boolean).join("\n")}\n    \n    # Fallback\n    return str(response)`),a.join("\n")}static generateResultsOutput(e){let t=`print(f"\\nCompleted {len(results)} API calls")\n    \n    success_count = sum(1 for r in results if r.get('success', False))\n    print(f"Successful: {success_count}/{len(results)}")\n    \n    if ${"json"===e.advanced.outputFormat||"both"===e.advanced.outputFormat?"True":"False"}:\n        with open('results.json', 'w') as f:\n            json.dump(results, f, indent=2)\n        print("Results saved to results.json")`;return e.options.csvOutput&&(t+="\n    \n    # Export to CSV\n    with open('results.csv', 'w', newline='') as f:\n        writer = csv.DictWriter(f, fieldnames=['model', 'prompt', 'success', 'latency_ms', 'response'])\n        writer.writeheader()\n        for result in results:\n            writer.writerow({\n                'model': result.get('model', ''),\n                'prompt': result.get('prompt', '')[:100] + '...' if len(result.get('prompt', '')) > 100 else result.get('prompt', ''),\n                'success': result.get('success', False),\n                'latency_ms': result.get('latency_ms', 0),\n                'response': str(result.get('response', ''))[:200] + '...' if len(str(result.get('response', ''))) > 200 else str(result.get('response', ''))\n            })\n    print(\"Results exported to results.csv\")"),t}static previewExportData(e){return Me.extractTrialData(e)}}const Le=Object.freeze(Object.defineProperty({__proto__:null,PythonExportService:De},Symbol.toStringTag,{value:"Module"})),Ne={class:"trial-info"},ze={class:"trial-stats"},Fe={class:"export-section"},Be={class:"mode-content"},qe={class:"mode-content"},Ve={class:"mode-content"},Ke={class:"export-section"},He={class:"options-grid"},Je={class:"export-section"},Ge={class:"preview-content"},Ye={class:"preview-info"},We=v({__name:"PythonExportModal",props:{trial:{}},emits:["close","exported"],setup(e,{emit:t}){const a=e,n=t,s=f("literal"),r=f({includeResults:!0,includeTiming:!0,includeErrorHandling:!0,parallelExecution:!1,rateLimit:!1,csvOutput:!1}),o=f(!1),i=g(()=>a.trial.progress.total),l=g(()=>a.trial.configurationSnapshots?.length||0),p=g(()=>a.trial.totalCombinations||0),c=g(()=>{const e=.5*i.value,t=r.value.includeResults?2*i.value:0;return Math.round(10+e+t)}),u=g(()=>{const e=.1*p.value,t=.3*l.value;return Math.round(8+e+t)}),d=g(()=>{const e=2*l.value,t=.05*p.value+.2*l.value;return Math.round(5+e+t)}),m=g(()=>{const e=a.trial.name.toLowerCase().replace(/\s+/g,"_"),t=(new Date).toISOString().split("T")[0];return`${e}_${s.value}_${t}.py`}),v=g(()=>{if("minimal"===s.value){return 100+30*l.value+(p.value+5*l.value)}return 100+20*Object.values(r.value).filter(e=>e).length+("literal"===s.value?5*i.value:0)});async function y(){o.value=!0;try{const e={mode:s.value,options:r.value,advanced:{timeout:3e4,rateLimit:10,maxConcurrent:5,outputFormat:"console"}};await De.downloadPythonScript(a.trial,e),n("exported",m.value),n("close")}catch(e){console.error("Export failed:",e),alert("Export failed: "+(e instanceof Error?e.message:"Unknown error"))}finally{o.value=!1}}return(e,t)=>{const a=b("a-button"),n=b("a-tag"),f=b("a-radio"),g=b("a-radio-group"),h=b("a-checkbox"),A=b("a-typography-text"),T=b("a-modal");return k(),_(T,{open:!0,title:"Export Python Script",width:"95vw",centered:!0,onCancel:t[8]||(t[8]=t=>e.$emit("close")),"wrap-class-name":"python-export-modal","body-style":{height:"90vh",overflow:"auto"}},{footer:x(()=>[S(a,{onClick:t[0]||(t[0]=t=>e.$emit("close"))},{default:x(()=>t[9]||(t[9]=[P("Cancel")])),_:1,__:[9]}),S(a,{type:"primary",onClick:y,loading:o.value},{default:x(()=>t[10]||(t[10]=[P(" Export Script ")])),_:1,__:[10]},8,["loading"])]),default:x(()=>[w("div",Ne,[w("h3",null,I(e.trial.name),1),w("div",ze,[S(n,null,{default:x(()=>[P(I(i.value)+" API calls",1)]),_:1}),S(n,null,{default:x(()=>[P(I(l.value)+" configurations",1)]),_:1}),S(n,null,{default:x(()=>[P(I(p.value)+" variable combinations",1)]),_:1})])]),w("div",Fe,[t[17]||(t[17]=w("h4",null,"Export Mode",-1)),S(g,{value:s.value,"onUpdate:value":t[1]||(t[1]=e=>s.value=e),class:"mode-options"},{default:x(()=>[S(f,{value:"literal",class:"mode-radio"},{default:x(()=>[w("div",Be,[t[11]||(t[11]=w("div",{class:"mode-title"},"Literal Calls",-1)),t[12]||(t[12]=w("div",{class:"mode-description"}," Store actual API calls as data lists. Fast execution, large file size. Best for reproducibility and debugging. ",-1)),S(n,{color:"blue",size:"small"},{default:x(()=>[P("~"+I(c.value)+"KB",1)]),_:1})])]),_:1}),S(f,{value:"hydrated",class:"mode-radio"},{default:x(()=>[w("div",qe,[t[13]||(t[13]=w("div",{class:"mode-title"},"Hydrated Template",-1)),t[14]||(t[14]=w("div",{class:"mode-description"}," Regenerate calls from prompt template + variables. Smaller file, matches original trial logic exactly. ",-1)),S(n,{color:"blue",size:"small"},{default:x(()=>[P("~"+I(u.value)+"KB",1)]),_:1})])]),_:1}),S(f,{value:"minimal",class:"mode-radio"},{default:x(()=>[w("div",Ve,[t[15]||(t[15]=w("div",{class:"mode-title"},"Minimal Script",-1)),t[16]||(t[16]=w("div",{class:"mode-description"}," Iterative script with clear loops. Shows experimental design upfront, easy to edit variables and parameters. Best for understanding and extending. ",-1)),S(n,{color:"blue",size:"small"},{default:x(()=>[P("~"+I(d.value)+"KB",1)]),_:1})])]),_:1})]),_:1},8,["value"])]),w("div",Ke,[t[24]||(t[24]=w("h4",null,"Options",-1)),w("div",He,[S(h,{checked:r.value.includeResults,"onUpdate:checked":t[2]||(t[2]=e=>r.value.includeResults=e)},{default:x(()=>t[18]||(t[18]=[w("span",null,"Include Results Data",-1),w("div",{class:"option-desc"},"Embed actual API responses for comparison",-1)])),_:1,__:[18]},8,["checked"]),S(h,{checked:r.value.includeTiming,"onUpdate:checked":t[3]||(t[3]=e=>r.value.includeTiming=e)},{default:x(()=>t[19]||(t[19]=[w("span",null,"Include Timing Analysis",-1),w("div",{class:"option-desc"},"Add latency measurement and reporting",-1)])),_:1,__:[19]},8,["checked"]),S(h,{checked:r.value.includeErrorHandling,"onUpdate:checked":t[4]||(t[4]=e=>r.value.includeErrorHandling=e)},{default:x(()=>t[20]||(t[20]=[w("span",null,"Enhanced Error Handling",-1),w("div",{class:"option-desc"},"Retry logic and detailed error reporting",-1)])),_:1,__:[20]},8,["checked"]),S(h,{checked:r.value.parallelExecution,"onUpdate:checked":t[5]||(t[5]=e=>r.value.parallelExecution=e)},{default:x(()=>t[21]||(t[21]=[w("span",null,"Parallel Execution",-1),w("div",{class:"option-desc"},"Run API calls concurrently (faster, more complex)",-1)])),_:1,__:[21]},8,["checked"]),S(h,{checked:r.value.rateLimit,"onUpdate:checked":t[6]||(t[6]=e=>r.value.rateLimit=e)},{default:x(()=>t[22]||(t[22]=[w("span",null,"Rate Limiting",-1),w("div",{class:"option-desc"},"Add delays between API calls",-1)])),_:1,__:[22]},8,["checked"]),S(h,{checked:r.value.csvOutput,"onUpdate:checked":t[7]||(t[7]=e=>r.value.csvOutput=e)},{default:x(()=>t[23]||(t[23]=[w("span",null,"CSV Results Export",-1),w("div",{class:"option-desc"},"Save results to CSV file",-1)])),_:1,__:[23]},8,["checked"])])]),w("div",Je,[t[25]||(t[25]=w("h4",null,"Script Preview",-1)),w("div",Ge,[S(A,{code:"",class:"preview-filename"},{default:x(()=>[P(I(m.value),1)]),_:1}),w("div",Ye,[S(n,{size:"small"},{default:x(()=>[P(I(v.value)+" lines",1)]),_:1}),S(n,{size:"small"},{default:x(()=>[P(I(s.value)+" mode",1)]),_:1})])])])]),_:1})}}});export{ke as T,je as _,We as a,Le as p};

import{a as o,_ as T}from"./index-DXsg4a_x.js";import"./vue-vendor-DPw1dQYc.js";import"./ui-vendor-IRGmExUJ.js";import"./utils-vendor-B76-F3_P.js";import"./tauri-vendor-1uBLmS9u.js";const h=typeof window<"u"&&(window.__TAURI_INTERNALS__||window.__TAURI__);typeof window<"u"&&o.info("ðŸ” Tauri detection:",{isTauri:h,__TAURI_INTERNALS__:window.__TAURI_INTERNALS__,__TAURI__:window.__TAURI__,location:window.location.href});let l=fetch,i=null,s=!1;h?(o.info("ðŸ¦€ Attempting to load Tauri HTTP plugin..."),i=T(()=>import("./tauri-vendor-1uBLmS9u.js").then(e=>e.d),[]).then(e=>{o.info("âœ… Tauri HTTP plugin loaded successfully",e),l=e.fetch,s=!0,o.info("ðŸ¦€ Tauri HTTP client loaded for CORS bypass")}).catch(e=>{o.error("âŒ Failed to load Tauri HTTP plugin:",e),o.warn("Failed to load Tauri HTTP plugin, using browser fetch:",e),l=fetch,s=!0})):(o.info("ðŸŒ Browser environment detected, using native fetch"),s=!0);async function w(){return s||i&&(await i,i=null),l}async function c(e,a={}){const d=`http://localhost:11434${e}`,r=window.location.protocol==="https:",u=await w();o.info("ðŸ”„ Making Ollama request:",{url:d,isHttps:r,protocol:window.location.protocol,usingTauriFetch:u!==fetch,fetchFn:u.name||"anonymous"});const m=a.timeout||3e4,f=new AbortController,p=setTimeout(()=>f.abort(),m);try{const n=await u(d,{...a,signal:f.signal,headers:{"Content-Type":"application/json",...a.headers}});return clearTimeout(p),n}catch(n){clearTimeout(p);const t=new Error;throw t.isHttps=r,n.name==="AbortError"?(t.type="timeout",t.message="Request to Ollama timed out",t.details=`The request took longer than ${m/1e3} seconds`):n.message?.includes("Failed to fetch")||n.message?.includes("NetworkError")?r?(t.type="cors",t.message="Cannot connect to Ollama from HTTPS site",t.details="Browser security prevents HTTPS sites from accessing local HTTP services. To use Ollama: 1) Download the desktop app, 2) Run Auditomatic locally, or 3) Configure Ollama with OLLAMA_ORIGINS=*"):(t.type="network",t.message="Cannot connect to Ollama",t.details="Make sure Ollama is running on your computer (http://localhost:11434)"):(t.type="unknown",t.message=n.message||"Unknown error connecting to Ollama",t.details=n.stack),o.warn("Ollama fetch error",{type:t.type,endpoint:e,isHttps:r,originalError:n.message}),t}}async function E(){try{return{available:(await c("/api/tags",{timeout:5e3})).ok}}catch(e){return{available:!1,error:e}}}async function R(){try{return await c("/api/tags",{method:"GET",headers:{Accept:"application/json"}}),{hasIssue:!1}}catch{return{hasIssue:!0,error:"Either Ollama is not running or CORS is not properly configured. Ensure Ollama is running and add OLLAMA_ORIGINS=* to your Ollama service configuration."}}}async function k(){const e=await c("/api/tags");if(!e.ok)throw new Error(`Failed to fetch models: ${e.status} ${e.statusText}`);return e.json()}async function F(e){const a=await c("/api/delete",{method:"DELETE",body:JSON.stringify({name:e})});if(!a.ok)throw new Error(`Failed to delete model: ${a.status} ${a.statusText}`)}export{E as checkOllamaConnection,F as deleteOllamaModel,R as detectOllamaIssue,k as fetchOllamaModels,c as ollamaFetch};

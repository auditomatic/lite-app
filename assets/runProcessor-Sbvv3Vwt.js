var e=Object.defineProperty,t=(t,r,s)=>((t,r,s)=>r in t?e(t,r,{enumerable:!0,configurable:!0,writable:!0,value:s}):t[r]=s)(t,"symbol"!=typeof r?r+"":r,s);import{d as r,r as s,b as o}from"./index-ChMukQl2.js";import{L as a,V as n,c as i}from"./VariableResolutionService-C7rGdAqP.js";import"./vendor-DdqHZeTC.js";import"./db-ftwlfnxb.js";import"./apiLogger-wE3EW76_.js";import"./safeJson-BfKuju6h.js";class l{classifyError(e){return e instanceof a?this.classifyLLMError(e):this.classifyGenericError(e)}classifyLLMError(e){const t=e.statusCode,r=e.message.toLowerCase(),s=e.provider;if(408===t)return{isRetryable:!0,isRateLimit:!1,errorCategory:"timeout",reason:"API call timeout - retryable with exponential backoff"};if(429===t){const t=this.extractRetryAfterSeconds(e);return{isRetryable:!0,isRateLimit:!0,retryAfterSeconds:t,errorCategory:"rate_limit",reason:`Rate limited - retry after ${t||"exponential backoff"} seconds`}}return t&&t>=500?{isRetryable:!0,isRateLimit:!1,errorCategory:"server_error",reason:`Server error (${t}) - retryable`}:401===t||403===t?{isRetryable:!1,isRateLimit:!1,errorCategory:"authentication",reason:"Authentication failed - check API key"}:t&&t>=400&&t<500?this.isRetryableClientError(r,s)?{isRetryable:!0,isRateLimit:!1,errorCategory:"client_error",reason:"Potentially temporary client error - retryable"}:{isRetryable:!1,isRateLimit:!1,errorCategory:"client_error",reason:`Client error (${t}) - not retryable`}:this.classifyProviderSpecificError(r,s)}classifyGenericError(e){const t=e.message.toLowerCase();return t.includes("network")||t.includes("connection")||t.includes("timeout")||t.includes("aborted")||t.includes("fetch")?{isRetryable:!0,isRateLimit:!1,errorCategory:"network",reason:"Network error - retryable"}:{isRetryable:!1,isRateLimit:!1,errorCategory:"unknown",reason:"Unknown error type - not retryable by default"}}classifyProviderSpecificError(e,t){return"openai"===t&&(e.includes("overloaded")||e.includes("engine overloaded"))?{isRetryable:!0,isRateLimit:!1,errorCategory:"server_error",reason:"OpenAI engine overloaded - retryable"}:"anthropic"===t&&(e.includes("overloaded")||e.includes("capacity"))?{isRetryable:!0,isRateLimit:!1,errorCategory:"server_error",reason:"Anthropic capacity issue - retryable"}:"openrouter"===t&&(e.includes("upstream")||e.includes("provider error"))?{isRetryable:!0,isRateLimit:!1,errorCategory:"server_error",reason:"OpenRouter upstream error - retryable"}:{isRetryable:!1,isRateLimit:!1,errorCategory:"unknown",reason:"Provider-specific error - not retryable by default"}}isRetryableClientError(e,t){return["temporarily","temporarily unavailable","too many requests","quota exceeded","rate limit","throttled"].some(t=>e.includes(t))}extractRetryAfterSeconds(e){if(e.details&&"object"==typeof e.details){const t=e.details.retry_after||e.details["retry-after"];if("number"==typeof t)return t;if("string"==typeof t){const e=parseInt(t,10);if(!isNaN(e))return e}}}}const c=new l;class u{constructor(e){t(this,"config"),this.config={maxRetries:5,baseDelayMs:2e3,maxDelayMs:6e4,jitterFactor:.1,backoffMultiplier:2,rateLimitBackoffMs:3e4,...e}}calculateDelay(e,t,r){if(t&&r)return Math.min(1e3*r,this.config.maxDelayMs);if(t)return this.config.rateLimitBackoffMs;const s=this.config.baseDelayMs*Math.pow(this.config.backoffMultiplier,e-1),o=s+s*this.config.jitterFactor*(2*Math.random()-1);return Math.min(Math.max(o,this.config.baseDelayMs),this.config.maxDelayMs)}shouldRetry(e){return e<=this.config.maxRetries}createRetryAttempt(e,t,r,s){return{attemptNumber:e,delayMs:t,timestamp:(new Date).toISOString(),error:r.message,errorCategory:s}}getConfig(){return{...this.config}}updateConfig(e){this.config={...this.config,...e}}calculateMaxRetryTime(){let e=0;for(let t=1;t<=this.config.maxRetries;t++)e+=this.calculateDelay(t,!1);return e}getRetrySummary(){const e=Math.round(this.calculateMaxRetryTime()/1e3);return`Up to ${this.config.maxRetries} retries over ~${e} seconds`}}const p=new u,d={openai:new u({maxRetries:5,baseDelayMs:3e3,rateLimitBackoffMs:6e4}),anthropic:new u({maxRetries:5,baseDelayMs:2e3,rateLimitBackoffMs:3e4}),openrouter:new u({maxRetries:6,baseDelayMs:5e3,rateLimitBackoffMs:45e3}),ollama:new u({maxRetries:3,baseDelayMs:1e3,rateLimitBackoffMs:5e3})};class g{constructor(){t(this,"locked",!1),t(this,"queue",[])}async acquire(e){return new Promise((t,r)=>{const s=async()=>{if(this.locked)this.queue.push(s);else{this.locked=!0;try{const r=await e();t(r)}catch(o){r(o)}finally{this.locked=!1;const e=this.queue.shift();e&&e()}}};s()})}isLocked(){return this.locked}getQueueLength(){return this.queue.length}}class m{constructor(){t(this,"abortController",null),t(this,"activeTasks",new Set),t(this,"completedCount",0),t(this,"errorClassifier",new l),t(this,"progressLock",new g),t(this,"retryTimeouts",new Set)}async processRun(e,t){this.cleanup(),this.completedCount=e.completed_tasks||0,this.abortController=new AbortController;try{const s=await r.designs.get(e.design_id);if(!s)throw new Error("Design not found");const o=await r.models.where("id").anyOf(e.models).toArray();if(0===o.length){const t=await r.models.toArray();throw console.error("TaskProcessor Error: No models found!"),console.error("  Run model IDs:",JSON.stringify(e.models)),console.error("  Available model IDs:",JSON.stringify(t.map(e=>e.id))),console.error("  Available models:",JSON.stringify(t.map(e=>({id:e.id,enabled:e.enabled})))),new Error("No models found")}const a=await this.generateTasks(e,s,o);await r.runs.update(e.id,{total_tasks:a.length,status:"running",updated_at:(new Date).toISOString()});const n=(await r.tasks.bulkAdd(a,{allKeys:!0})).map((e,t)=>({id:e,task:a[t]})),i=[];for(let r=0;r<t.concurrency;r++){const a=this.processWorker(n,o,e,s,t);i.push(a),console.log(`[TaskProcessor] Created worker ${r+1}/${t.concurrency}`)}console.log(`[TaskProcessor] Starting ${i.length} workers, waiting for completion...`);const l=Date.now();await Promise.all(i);const c=Date.now()-l;console.log(`[TaskProcessor] All workers completed in ${c}ms, updating run status...`),console.log("[TaskProcessor] Querying final tasks...");const u=await r.tasks.where("run_id").equals(e.id).toArray();console.log(`[TaskProcessor] Got ${u.length} final tasks, filtering...`);const p=u.filter(e=>"completed"===e.status).length,d=u.filter(e=>"error"===e.status).length;console.log(`[TaskProcessor] Completed: ${p}, Errors: ${d}`),console.log("[TaskProcessor] Updating run record..."),await r.runs.update(e.id,{status:"completed",completed_tasks:p,error_count:d,updated_at:(new Date).toISOString()}),console.log("[TaskProcessor] Run update complete!")}finally{this.cleanup()}}async generateTasks(e,t,r){const s=[],o=await this.getVariableValuesWithAttributes(t),a=this.generateCombinationsWithAttributes(o);for(const i of r)for(let r=1;r<=e.parameters.repetitions_per_prompt;r++)for(const o of a){const a=n.getInstance().processTemplate(t.prompt_template,o);s.push({run_id:e.id,model:i.id,prompt:a,variables:o,repetition:r,status:"pending",created_at:(new Date).toISOString()})}return s}async getVariableValues(e){const t=n.getInstance();return await t.resolveDesignVariables(e)}async getVariableValuesWithAttributes(e){const t=n.getInstance();return await t.resolveVariablesWithAttributes(e)}generateCombinations(e){const t=Object.keys(e);if(0===t.length)return[{}];const r=[];return function s(o,a){if(o===t.length)return void r.push({...a});const n=t[o];for(const t of e[n])a[n]=t,s(o+1,a)}(0,{}),r}generateCombinationsWithAttributes(e){const{values:t,attributes:r}=e,s=Object.keys(t);if(0===s.length)return[{}];const o=[];return function e(a,n){if(a===s.length)return void o.push({...n});const i=s[a],l=t[i],c=r[i];for(let t=0;t<l.length;t++){const r=l[t],s=c[t];n[i]=r;for(const[e,t]of Object.entries(s))n[`${i}_${e}`]=String(t);e(a+1,n);for(const e of Object.keys(s))delete n[`${i}_${e}`]}}(0,{}),o}async processWorker(e,t,o,a,n){const l=Math.random().toString(36).substring(7);for(console.log(`[Worker ${l}] Starting worker, initial queue length: ${e.length}`);e.length>0&&!this.abortController?.signal.aborted;){console.log(`[Worker ${l}] Loop iteration - queue length: ${e.length}, active tasks: ${this.activeTasks.size}, completed: ${this.completedCount}`);const u=e.length,g=e.shift(),m=e.length;if(console.log(`[Worker ${l}] Queue shift - before: ${u}, after: ${m}, got:`,g?`task ${g.id}`:"undefined"),!g){console.log(`[Worker ${l}] No item received, breaking from worker loop`);break}const{id:y,task:f}=g;console.log(`[Worker ${l}] About to process task ${y}`),this.activeTasks.add(y);const h=t.find(e=>e.id===f.model);if(h)try{if(this.abortController?.signal.aborted){await r.tasks.update(y,{status:"cancelled"});continue}if(console.log(`[TaskProcessor] Starting task ${y}`),await r.tasks.update(y,{status:"processing"}),console.log(`[TaskProcessor] Task ${y} status updated to processing`),this.abortController?.signal.aborted){await r.tasks.update(y,{status:"cancelled"});continue}const e=await i({model:h.id,prompt:f.prompt,temperature:o.parameters.temperature,max_tokens:o.parameters.max_tokens,output_format:a.output_format,output_type:a.output_type},h);if(this.abortController?.signal.aborted){await r.tasks.update(y,{status:"cancelled"});continue}let t={};"json"===a.output_format&&void 0!==e.extracted_value?t={answer:e.extracted_value}:a.extract_pattern&&(t=this.parseResults(e.content,a.extract_pattern)),console.log(`[TaskProcessor] Completing task ${y}`),await r.tasks.update(y,{status:"completed",result:e.content,parsed_results:t,response_time:e.response_time,usage:e.usage,api_call_log:e.api_call_log,completed_at:(new Date).toISOString()}),console.log(`[TaskProcessor] Task ${y} updated to completed`),console.log(`[Worker ${l}] Starting research log for task ${y}`);const c=Date.now();e.api_call_log&&await s.logAPICall(y,h.id,{request_url:e.api_call_log.request.url,response_status:e.api_call_log.response.status,response_time_ms:e.api_call_log.response.timing_ms,cost_estimate:e.api_call_log.cost_estimate.estimated_cost_usd,tokens_used:{input:e.api_call_log.cost_estimate.input_tokens,output:e.api_call_log.cost_estimate.output_tokens}});const u=Date.now()-c;if(console.log(`[Worker ${l}] Research log completed for task ${y} in ${u}ms`),await this.updateProgress(o,l,y),n.onTaskComplete){const e=await r.tasks.get(y);e&&n.onTaskComplete(e)}n.onProgress&&n.onProgress(this.completedCount,o.total_tasks)}catch(c){const t=await r.tasks.get(y);if(!t){console.error(`[TaskProcessor] Task ${y} not found for retry logic`),this.activeTasks.delete(y);continue}const a=this.errorClassifier.classifyError(c),i=t.retry_count||0,u=5;if(a.isRetryable&&i<u){const n=(d[h.provider]||p).calculateDelay(i+1,a.isRateLimit,a.retryAfterSeconds),l={attemptNumber:i+1,delayMs:n,timestamp:(new Date).toISOString(),error:c instanceof Error?c.message:String(c),errorCategory:a.errorCategory};await r.tasks.update(y,{retry_count:i+1,retry_attempts:[...t.retry_attempts||[],l],last_retry_at:(new Date).toISOString(),retry_after:a.retryAfterSeconds?new Date(Date.now()+1e3*a.retryAfterSeconds).toISOString():void 0}),await s.logRetryAttempt(y,{attempt_number:l.attemptNumber,delay_ms:l.delayMs,error_category:l.errorCategory,error_message:l.error,will_retry_at:new Date(Date.now()+n).toISOString()}),console.log(`[TaskProcessor] Task ${y} will retry in ${n}ms (attempt ${l.attemptNumber}/${u})`);const m=setTimeout(async()=>{if(this.retryTimeouts.delete(m),!this.abortController?.signal.aborted){const t=await r.runs.get(o.id);t&&"running"===t.status?e.push(g):console.log(`[TaskProcessor] Task ${y} retry cancelled - run is ${t?.status||"missing"}`)}},n);this.retryTimeouts.add(m)}else{const e=c instanceof Error?c.message:String(c),t=i>=u?`Max retries (${u}) exceeded. Last error: ${e}`:`Non-retryable error: ${e}`;if(await r.tasks.update(y,{status:"error",error:t,completed_at:(new Date).toISOString()}),await this.updateProgressWithError(o,l,y),await s.logTaskFailure(y,{final_error:t,retry_count:i,error_category:a.errorCategory,is_retryable:a.isRetryable}),n.onTaskError){const e=await r.tasks.get(y);e&&n.onTaskError(e,c)}n.onProgress&&n.onProgress(this.completedCount,o.total_tasks)}}finally{console.log(`[Worker ${l}] Removing task ${y} from active tasks`),this.activeTasks.delete(y),console.log(`[Worker ${l}] Task ${y} removed, active tasks now: ${this.activeTasks.size}`)}else console.error(`[TaskProcessor] Model ${f.model} not found for task ${y}`),await r.tasks.update(y,{status:"error",error:`Model ${f.model} not found`,completed_at:(new Date).toISOString()}),this.activeTasks.delete(y)}console.log(`[Worker ${l}] Worker loop ended - queue length: ${e.length}, active tasks: ${this.activeTasks.size}, completed: ${this.completedCount}`)}stop(){this.abortController?.abort(),this.cleanup()}pause(){this.stop()}resume(){}cleanup(){this.abortController&&(this.abortController.abort(),this.abortController=null),this.retryTimeouts.forEach(e=>clearTimeout(e)),this.retryTimeouts.clear(),this.activeTasks.clear()}dispose(){this.cleanup()}async updateProgress(e,t,s){this.abortController?.signal.aborted?console.log(`[Worker ${t}] Skipping progress update for task ${s} - run is stopped`):await this.progressLock.acquire(async()=>{if(this.abortController?.signal.aborted)return;const o=await r.runs.get(e.id);if(!o||"stopped"===o.status)return void console.log(`[Worker ${t}] Run ${e.id} is ${o?.status||"missing"}, skipping progress update`);this.completedCount+=1,console.log(`[TaskProcessor] Completed count now: ${this.completedCount}`),console.log(`[Worker ${t}] Starting run progress update for task ${s}`);const a=Date.now();await r.runs.update(e.id,{completed_tasks:this.completedCount,updated_at:(new Date).toISOString()});const n=Date.now()-a;console.log(`[Worker ${t}] Run progress updated for task ${s} in ${n}ms`)})}async updateProgressWithError(e,t,s){this.abortController?.signal.aborted?console.log(`[Worker ${t}] Skipping error progress update for task ${s} - run is stopped`):await this.progressLock.acquire(async()=>{if(this.abortController?.signal.aborted)return;const o=await r.runs.get(e.id);o&&"stopped"!==o.status?(this.completedCount+=1,await r.runs.update(e.id,{completed_tasks:this.completedCount,error_count:(e.error_count||0)+1,updated_at:(new Date).toISOString()}),console.log(`[Worker ${t}] Progress updated with error for task ${s}, completed: ${this.completedCount}`)):console.log(`[Worker ${t}] Run ${e.id} is ${o?.status||"missing"}, skipping error update`)})}parseResults(e,t){if(!t||!e)return{response:e};try{const s="string"==typeof t?{match:t,replace:void 0}:t,o=new RegExp(s.match,"gm"),a={};let n,i=0;const l=1e3,c=100;let u=0;for(;null!==(n=o.exec(e))&&i<l&&u<c;)if(i++,u++,n.index===o.lastIndex&&o.lastIndex++,n.groups)Object.assign(a,n.groups);else if(n.length>1){for(let e=1;e<n.length;e++)if(void 0!==n[e]){a[1===u?`match_${e}`:`match_${u}_${e}`]=n[e]}}else{a[1===u?"match":`match_${u}`]=n[0]}if(i>=l&&(console.warn("Pattern parsing stopped due to complexity limit:",t),a._parsing_warning="Parsing stopped due to complexity limit"),u>=c&&(console.warn("Pattern parsing stopped due to match limit:",t),a._parsing_warning="Parsing stopped due to match limit"),s.replace)for(const[e,t]of Object.entries(a))if("string"==typeof t&&"_parsing_warning"!==e)try{const r=new RegExp(s.match,"g"),o=t.replace(r,s.replace);a[e]=o}catch(r){console.warn("Error applying replace pattern:",r)}for(const[e,t]of Object.entries(a))if("string"==typeof t&&"_parsing_warning"!==e){const r=t.replace(/,/g,""),s=parseFloat(r);!isNaN(s)&&isFinite(s)?a[e]=s:a[e]=r}return a}catch(s){return console.error("Error parsing results with pattern:",t,s),{_parsing_error:s instanceof Error?s.message:"Unknown parsing error"}}}}class y{async analyzeFailedTasks(e){const t=await r.tasks.where("[run_id+status]").equals([e,"error"]).toArray();let s=0,o=0,a=0,n=0,i=0;const l=new Date;for(const r of t){if((r.retry_count||0)>=p.getConfig().maxRetries)a++;else{if(r.retry_after){if(l<new Date(r.retry_after)){n++;continue}}if(r.error){const e=new Error(r.error);c.classifyError(e).isRetryable?(s++,i++):o++}else o++}}const u=this.estimateRetryTime(i);return{totalFailedTasks:t.length,retryableFailedTasks:s,nonRetryableFailedTasks:o,maxRetriesExceeded:a,rateLimitedTasks:n,readyToRetry:i,estimatedRetryTime:u}}async getRetryableTasks(e){const t=await r.tasks.where("[run_id+status]").equals([e,"error"]).toArray(),s=new Date,o=[];for(const r of t){if(!((r.retry_count||0)>=p.getConfig().maxRetries)){if(r.retry_after){if(s<new Date(r.retry_after))continue}if(r.error){const e=new Error(r.error);c.classifyError(e).isRetryable&&o.push(r)}}}return o}async retryFailedTasks(e,t){const o=Date.now(),a=await r.runs.get(e);if(!a)throw new Error("Run not found");const n=await r.designs.get(a.design_id);if(!n)throw new Error("Design not found");const i=await r.models.where("id").anyOf(a.models).toArray();if(0===i.length)throw new Error("No models found");const l=await this.getRetryableTasks(e);if(0===l.length)return{totalTasks:0,successfulRetries:0,failedRetries:0,skippedTasks:0,results:[],duration:Date.now()-o};await s.logOperation("run",e,"run_start",{operation:"bulk_retry",total_tasks:l.length});const c=[];let u=0,p=0,d=0;const g=new Array(t?.maxConcurrency||3).fill(null),m=[...l],y=async()=>{for(;m.length>0;){const r=m.shift();if(!r)break;try{const e=await this.retryTask(r,a,n,i);c.push(e),e.success?u++:p++,t?.onTaskRetry&&t.onTaskRetry(e)}catch(e){const t={taskId:r.id,success:!1,error:e instanceof Error?e.message:String(e),retryAttempt:{attemptNumber:(r.retry_count||0)+1,delayMs:0,timestamp:(new Date).toISOString(),error:e instanceof Error?e.message:String(e),errorCategory:"retry_error"}};c.push(t),p++}d++,t?.onProgress&&t.onProgress(d,l.length)}};return await Promise.all(g.map(()=>y())),await this.updateRunRetryStats(e),await s.logOperation("run",e,"run_complete",{operation:"bulk_retry",successful_retries:u,failed_retries:p,duration_ms:Date.now()-o}),{totalTasks:l.length,successfulRetries:u,failedRetries:p,skippedTasks:0,results:c,duration:Date.now()-o}}async retryTask(e,t,o,a){const n=a.find(t=>t.id===e.model);if(!n)throw new Error(`Model ${e.model} not found`);const l=(e.retry_count||0)+1,u=d[n.provider]||p;if(l>u.getConfig().maxRetries)throw new Error(`Max retries (${u.getConfig().maxRetries}) exceeded`);await r.tasks.update(e.id,{status:"processing",retry_count:l,last_retry_at:(new Date).toISOString()});try{const a=await i({model:n.id,prompt:e.prompt,temperature:t.parameters.temperature,max_tokens:t.parameters.max_tokens,output_format:o.output_format,output_type:o.output_type},n);let c={};"json"===o.output_format&&void 0!==a.extracted_value?c={answer:a.extracted_value}:o.extract_pattern&&(c={content:a.content});const u={attemptNumber:l,delayMs:0,timestamp:(new Date).toISOString(),error:"",errorCategory:"success"},p=[...e.retry_attempts||[],u];return await r.tasks.update(e.id,{status:"completed",result:a.content,parsed_results:c,response_time:a.response_time,usage:a.usage,api_call_log:a.api_call_log,completed_at:(new Date).toISOString(),retry_attempts:p,retry_after:void 0}),a.api_call_log&&await s.logAPICall(e.id,n.id,{request_url:a.api_call_log.request.url,response_status:a.api_call_log.response.status,response_time_ms:a.api_call_log.response.timing_ms,cost_estimate:a.api_call_log.cost_estimate.estimated_cost_usd,tokens_used:{input:a.api_call_log.cost_estimate.input_tokens,output:a.api_call_log.cost_estimate.output_tokens}}),{taskId:e.id,success:!0,retryAttempt:u}}catch(g){const t=c.classifyError(g),s={attemptNumber:l,delayMs:0,timestamp:(new Date).toISOString(),error:g.message,errorCategory:t.errorCategory},o=[...e.retry_attempts||[],s];let a;if(t.isRateLimit&&t.retryAfterSeconds){const e=new Date;e.setSeconds(e.getSeconds()+t.retryAfterSeconds),a=e.toISOString()}return await r.tasks.update(e.id,{status:"error",error:g.message,completed_at:(new Date).toISOString(),retry_attempts:o,retry_after:a}),{taskId:e.id,success:!1,error:g.message,retryAttempt:s}}}async updateRunRetryStats(e){const t=await r.tasks.where("run_id").equals(e).toArray(),s=t.filter(e=>"completed"===e.status).length,o=t.filter(e=>"error"===e.status).length;await r.runs.update(e,{completed_tasks:s,error_count:o,updated_at:(new Date).toISOString()})}estimateRetryTime(e){if(0===e)return"0 seconds";const t=e/3*5e3;return t<6e4?`~${Math.round(t/1e3)} seconds`:t<36e5?`~${Math.round(t/6e4)} minutes`:`~${Math.round(t/36e5)} hours`}}const f=new class{constructor(){t(this,"processors",new Map),t(this,"retryService",new y)}async startRun(e){const t=o(),r=await t.getRunById(e);if(!r)throw new Error("Run not found");if(this.processors.has(e))throw new Error("Run is already being processed");const s=new m;this.processors.set(e,s);try{await s.processRun(r,{concurrency:r.parameters.concurrency||3,onProgress:async r=>{await t.updateRun(e,{completed_tasks:r})},onTaskComplete:e=>{},onTaskError:(e,t)=>{}})}finally{const t=this.processors.get(e);t&&(t.dispose(),this.processors.delete(e))}}stopRun(e){const t=this.processors.get(e);t&&(t.stop(),t.dispose(),this.processors.delete(e))}pauseRun(e){const t=this.processors.get(e);t&&t.pause()}resumeRun(e){}isRunning(e){return this.processors.has(e)}stopAll(){for(const[,e]of this.processors)e.stop(),e.dispose();this.processors.clear()}async retryFailedTasks(e,t){if(this.processors.has(e))throw new Error("Cannot retry tasks while run is still processing");const r=await this.retryService.retryFailedTasks(e,{maxConcurrency:t?.concurrency||3,onProgress:t?.onProgress});return{retriedCount:r.totalTasks,successCount:r.successfulRetries,failedCount:r.failedRetries,errors:r.results.filter(e=>!e.success).map(e=>({taskId:e.taskId,error:e.error||"Unknown error"}))}}async getRetryAnalysis(e){const t=await this.retryService.analyzeFailedTasks(e);return{totalFailed:t.totalFailedTasks,retryableCount:t.retryableFailedTasks,nonRetryableCount:t.nonRetryableFailedTasks,errorsByCategory:{},tasksByError:[]}}dispose(){this.stopAll()}};export{f as runProcessor};
